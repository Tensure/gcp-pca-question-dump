{
    "count": 70,
    "next": null,
    "previous": null,
    "results": [
        {
            "_class": "assessment",
            "id": 82163914,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You want to have durable storage in a Kubernetes cluster. Pods are ephemeral, so they may be deleted or recreated. As a cloud architect, you want to decouple pods from persistent storage. What Kubernetes mechanism should you use? </p>",
                "relatedLectureIds": [],
                "links": [],
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>PersistentVolumes -&gt;&nbsp;Correct. PersistentVolumes in Kubernetes provide a way to decouple pods from persistent storage. They are an abstraction that allows pods to claim and use durable storage resources in a decoupled manner. PersistentVolumes can be created and managed separately from pods and can survive pod restarts or deletions. Pods can then request access to PersistentVolumes through PersistentVolumeClaims, ensuring durable storage is available even when pods are recreated or deleted.</p><p><br></p><p>Deployments -&gt;&nbsp;Incorrect. Deployments in Kubernetes are primarily used for managing and updating applications by controlling the creation and scaling of ReplicaSets. </p><p><br></p><p>ReplicaSets -&gt;&nbsp;Incorrect. ReplicaSets are used in Kubernetes to ensure a specified number of pod replicas are running at all times. They help maintain the desired pod count and handle scaling.</p><p><br></p><p>DeamonSet -&gt;&nbsp;Incorrect. DaemonSets are used to ensure that a specific pod runs on every node in a Kubernetes cluster. They are typically used for running background or system-level processes on every node.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes#persistentvolumes</p>",
                "answers": [
                    "<p>PersistentVolumes</p>",
                    "<p>Deployments</p>",
                    "<p>ReplicaSets</p>",
                    "<p>DeamonSet</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You want to have durable storage in a Kubernetes cluster. Pods are ephemeral, so they may be deleted or recreated. As a cloud architect, you want to decouple pods from persistent storage. What Kubernetes mechanism should you use?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163916,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>An e-commerce company runs all workload in the on-premises data center. In case the on-premises data center is not available, they want to use Google Cloud as a disaster recovery infrastructure. As a cloud architect, what network topology should you use in this case?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Mirrored topology -&gt; Correct. A mirrored topology is a network topology that replicates the on-premises network in the cloud. This approach enables you to create an exact replica of your on-premises environment in the cloud, including virtual machines, storage, and network configurations. By doing so, the mirrored topology enables your workloads to failover to the cloud seamlessly in the event of a disaster, without any interruption in service.</p><p><br></p><p>Meshed topology -&gt; Incorrect. A meshed topology is a network topology that connects all devices in a network to one another. It is not specifically designed for disaster recovery.</p><p><br></p><p>Handover topology -&gt; Incorrect. A handover topology is a network topology that enables a device or service to switch from one network to another. It is not specifically designed for disaster recovery.</p><p><br></p><p>Gated ingress and egress topology -&gt; Incorrect. The idea of the mirrored topology is to have the cloud computing environment and private computing environment mirror each other. This is the correct answer.</p><p><br></p><p>https://cloud.google.com/architecture/hybrid-and-multi-cloud-network-topologies#mirrored</p>",
                "answers": [
                    "<p>Mirrored topology</p>",
                    "<p>Meshed topology</p>",
                    "<p>Handover topology</p>",
                    "<p>Gated ingress and egress topology</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "An e-commerce company runs all workload in the on-premises data center. In case the on-premises data center is not available, they want to use Google Cloud as a disaster recovery infrastructure. As a cloud architect, what network topology should you use in this case?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163862,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you are managing a project that consists of a single Virtual Private Cloud (VPC) and a single subnetwork located in the <code>us-west1</code> region. Within this subnetwork, there is a Compute Engine instance hosting an application. Now, your development team intends to deploy a new instance within the same project, but in the <code>europe-central2</code> region. They require access to the application and wish to adhere to Google's best practices. As a cloud architect, what guidance should you provide in this situation?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should create a subnetwork in the same VPC, in <code>europe-central2</code> region. Than, create a new instance in the new subnetwork and use the first instance's private address as the endpoint. -&gt;&nbsp;Correct. By creating a subnetwork in the same VPC but in a different region, the development team can deploy the new instance in <code>europe-central2</code> region while still maintaining connectivity to the existing application hosted in the us-west1 region. They can use the first instance's private address as the endpoint to access the application, leveraging the VPC network connectivity.</p><p><br></p><p>They should create a VPC and a subnetwork in <code>europe-central2</code> region. Than, expose the application with an internal load balancer, and finally create a new instance in the new subnetwork and use the load balancer's address as the endpoint. -&gt;&nbsp;Incorrect. It suggests creating a new VPC and a subnetwork in the <code>europe-central2</code> region, along with an internal load balancer. While load balancers can distribute traffic, in this case, it is not necessary as there is only one instance hosting the application.</p><p><br></p><p>They should create a subnetwork in the same VPC, in <code>europe-central2</code> region. Than, use Cloud VPN to connect these two subnetworks, and finally create a new instance in the new subnetwork and use the first instance's private address as the endpoint. -&gt;&nbsp;Incorrect. Cloud VPN is typically used to establish secure connections between on-premises networks and VPC networks, rather than connecting subnetworks within the same VPC.</p><p><br></p><p>They should create a VPC and a subnetwork in <code>europe-central2</code> region. Than, peer the 2 VPCs, and finally create a new instance in the new subnetwork and use the first instance's private address as the endpoint. -&gt;&nbsp;Incorrect. VPC peering is used to establish connectivity between different VPC networks, but in this case, there is a requirement to deploy the new instance within the same project and VPC.</p><p><br></p><p>https://cloud.google.com/vpc/docs/vpc#vpc_networks_and_subnets</p>",
                "answers": [
                    "<p>They should create a subnetwork in the same VPC, in <code>europe-central2</code> region. Than, create a new instance in the new subnetwork and use the first instance's private address as the endpoint.</p>",
                    "<p>They should create a VPC and a subnetwork in <code>europe-central2</code> region. Than, expose the application with an internal load balancer, and finally create a new instance in the new subnetwork and use the load balancer's address as the endpoint.</p>",
                    "<p>They should create a subnetwork in the same VPC, in <code>europe-central2</code> region. Than, use Cloud VPN to connect these two subnetworks, and finally create a new instance in the new subnetwork and use the first instance's private address as the endpoint.</p>",
                    "<p>They should create a VPC and a subnetwork in <code>europe-central2</code> region. Than, peer the 2 VPCs, and finally create a new instance in the new subnetwork and use the first instance's private address as the endpoint.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you are managing a project that consists of a single Virtual Private Cloud (VPC) and a single subnetwork located in the us-west1 region. Within this subnetwork, there is a Compute Engine instance hosting an application. Now, your development team intends to deploy a new instance within the same project, but in the europe-central2 region. They require access to the application and wish to adhere to Google's best practices. As a cloud architect, what guidance should you provide in this situation?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163864,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your team has created an updated version of an application that is currently hosted on the App Engine Standard environment. You aim to migrate 2% of your users to the new version while minimizing complexity. What course of action would you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should deploy a new version in the same application and split the traffic (98% to 2%). -&gt; Correct. It suggests deploying the new version in the same application and splitting the traffic between the old and new versions. This approach is the simplest and requires minimal changes to the current deployment. The traffic splitting can be done using the App Engine's built-in traffic splitting feature, which allows directing a percentage of traffic to a specific version. This way, 2% of the traffic will be sent to the new version, and the remaining 98% will continue to use the old version until further changes are made.</p><p><br></p><p>You should deploy a new version in the same application and use the <code>--migrate</code> option. -&gt; Incorrect. The <code>--migrate</code> option is used for migrating traffic from one version to another within the same application, and it doesn't split the traffic.</p><p><br></p><p>You should create a new App Engine application in the same project. Deploy a new version in that application. Use the App Engine to split the traffic. -&gt; Incorrect. It suggest creating a new application which introduces unnecessary complexity and requires additional configuration and management effort.</p><p><br></p><p>You should create a new App Engine application in the same project. Deploy a new version in that application. Configure your network load balancer to send 2% of the traffic to that new application. -&gt; Incorrect. It suggest creating a new application or configuring a network load balancer, which introduces unnecessary complexity and requires additional configuration and management effort.</p><p><br></p><p>https://cloud.google.com/appengine/docs/standard/python/splitting-traffic</p>",
                "answers": [
                    "<p>You should deploy a new version in the same application and split the traffic (98% to 2%).</p>",
                    "<p>You should deploy a new version in the same application and use the <code>--migrate</code> option.</p>",
                    "<p>You should create a new App Engine application in the same project. Deploy a new version in that application. Use the App Engine to split the traffic.</p>",
                    "<p>You should create a new App Engine application in the same project. Deploy a new version in that application. Configure your network load balancer to send 2% of the traffic to that new application.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your team has created an updated version of an application that is currently hosted on the App Engine Standard environment. You aim to migrate 2% of your users to the new version while minimizing complexity. What course of action would you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163866,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A&nbsp;data science team wants to analyze very large data sets and prepares them for a machine learning model. As a cloud architect, which service should you recommend to use for interactive queries and online analytics?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>BigQuery -&gt; Correct.&nbsp; BigQuery is a fully managed, highly scalable, and cost-effective cloud data warehouse that enables interactive analysis of large datasets using SQL-like queries. It is ideal for analyzing large datasets and preparing them for machine learning models. BigQuery allows you to store and query data using a pay-as-you-go model, and it supports real-time analysis with streaming data.</p><p><br></p><p>Cloud Datastore -&gt; Incorrect. It is a NoSQL document database that is optimized for storing and querying large amounts of semi-structured data. It is not specifically designed for interactive queries and online analytics.</p><p><br></p><p>Cloud Bigtable -&gt; Incorrect. It is a NoSQL wide-column database that is optimized for scalability and high-performance read/write operations. It is designed for use cases that require low latency and high throughput, such as AdTech and IoT, but it may not be the best option for interactive queries and online analytics.</p><p><br></p><p>Cloud Spanner -&gt; Incorrect. It is a globally distributed, horizontally scalable, and strongly consistent relational database. It is ideal for mission-critical, transaction-intensive applications that require high availability and scalability. However, it may not be the best option for interactive queries and online analytics.</p><p><br></p><p>https://cloud.google.com/bigquery/docs</p>",
                "answers": [
                    "<p>BigQuery</p>",
                    "<p>Cloud Datastore</p>",
                    "<p>Cloud Bigtable</p>",
                    "<p>Cloud Spanner</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A&nbsp;data science team wants to analyze very large data sets and prepares them for a machine learning model. As a cloud architect, which service should you recommend to use for interactive queries and online analytics?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163868,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You have completed the deployment of a brand new regional Kubernetes Engine cluster, where the default pool in the first zone consists of four machines. Additionally, you have maintained the default number of zones during the deployment. How many Compute Engine instances have been deployed and are being billed to your account?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>12 -&gt;&nbsp;Correct. Four nodes are deployed in each of three zones. A control plane node is deployed in each zone but it is not billed against your account.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs/quickstart</p>",
                "answers": [
                    "<p>12</p>",
                    "<p>4</p>",
                    "<p>8</p>",
                    "<p>16</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You have completed the deployment of a brand new regional Kubernetes Engine cluster, where the default pool in the first zone consists of four machines. Additionally, you have maintained the default number of zones during the deployment. How many Compute Engine instances have been deployed and are being billed to your account?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163870,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are taking charge of the migration process for a legacy application, moving it from an on-premises data center to the Google Cloud Platform. This application is responsible for handling SSL encrypted traffic from clients across the globe on TCP port 443. Which GCP load balancing service should you employ to minimize latency for all clients?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>SSL Proxy Load Balancer -&gt; Correct. The SSL Proxy Load Balancer is specifically designed to handle SSL-encrypted traffic. It terminates SSL connections at the load balancer and then forwards the decrypted traffic to the backend instances. By terminating SSL at the load balancer, it reduces the latency associated with SSL handshake and encryption for the backend instances, resulting in minimized latency for all clients.</p><p><br></p><p>Network TCP/UDP Load Balancer -&gt;&nbsp;Incorrect. The Network TCP/UDP Load Balancer operates at the transport layer (Layer 4) and does not provide SSL termination or decryption capabilities. It is designed for load balancing TCP or UDP traffic at the network level.</p><p><br></p><p>Internal TCP/UDP Load Balancer -&gt;&nbsp;Incorrect. The Internal TCP/UDP Load Balancer is used for internal load balancing within a VPC network and does not provide SSL termination capabilities for handling traffic from external clients.</p><p><br></p><p>External HTTP(S) Load Balancer -&gt;&nbsp;Incorrect. The External HTTP(S) Load Balancer is specifically designed for HTTP(S) traffic and operates at the application layer (Layer 7).</p><p><br></p><p>https://cloud.google.com/load-balancing/docs/ssl</p>",
                "answers": [
                    "<p>SSL Proxy Load Balancer</p>",
                    "<p>Network TCP/UDP Load Balancer</p>",
                    "<p>Internal TCP/UDP Load Balancer</p>",
                    "<p>External HTTP(S) Load Balancer</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are taking charge of the migration process for a legacy application, moving it from an on-premises data center to the Google Cloud Platform. This application is responsible for handling SSL encrypted traffic from clients across the globe on TCP port 443. Which GCP load balancing service should you employ to minimize latency for all clients?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163872,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>The game's backend APIs run on a fleet of virtual machines behind a Managed Instance Group with autoscaling enabled. The scaling policy on this group adds more instances if the CPU utilization is consistently over 80%, and to scale down when the CPU utilization is consistently lower than 60%. You've noticed that autoscaling adds more virtual machines than necessary when scaling up, and you suspect that this may be due to a misconfiguration in health checks - the initial health check latency is set to 30 seconds. Each virtual machine takes less than 3 minutes to be ready to process requests. What can you do to fix this issue?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You can update the autoscaling health check to increase the initial delay to 200 seconds. -&gt; Correct. By increasing the initial delay of the health check to 200 seconds, you allow more time for the virtual machines to become fully ready to process requests before autoscaling takes place. Since each virtual machine takes less than 3 minutes to be ready, increasing the initial delay will help prevent unnecessary scaling.</p><p><br></p><p>You can update the autoscaling health check from HTTP to TCP. -&gt;&nbsp;Incorrect. Changing the health check protocol from HTTP to TCP may have implications on the health monitoring and may not directly address the problem of unnecessary scaling due to misconfiguration in health checks.</p><p><br></p><p>You can update the managed instances template to set the maximum instances to 3. -&gt;&nbsp;Incorrect. Limiting the maximum instances to 3 would restrict the scaling, but it does not address the underlying problem of unnecessary scaling caused by the misconfiguration in health checks.</p><p><br></p><p>You can update the managed instances template to set the minimum instances to 3. -&gt;&nbsp;Incorrect. Setting the minimum instances to 3 would enforce a higher baseline number of instances, but it does not directly address the issue of unnecessary scaling caused by the misconfiguration in health checks.</p><p><br></p><p>https://cloud.google.com/compute/docs/instance-groups/autohealing-instances-in-migs</p>",
                "answers": [
                    "<p>You can update the autoscaling health check to increase the initial delay to 200 seconds.</p>",
                    "<p>You can update the autoscaling health check from HTTP to TCP.</p>",
                    "<p>You can update the managed instances template to set the maximum instances to 3.</p>",
                    "<p>You can update the managed instances template to set the minimum instances to 3.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "The game's backend APIs run on a fleet of virtual machines behind a Managed Instance Group with autoscaling enabled. The scaling policy on this group adds more instances if the CPU utilization is consistently over 80%, and to scale down when the CPU utilization is consistently lower than 60%. You've noticed that autoscaling adds more virtual machines than necessary when scaling up, and you suspect that this may be due to a misconfiguration in health checks - the initial health check latency is set to 30 seconds. Each virtual machine takes less than 3 minutes to be ready to process requests. What can you do to fix this issue?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163874,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>After adding a new version of your application in App Engine Standard, users have reported experiencing slow performance issues. Your immediate objective is to revert to the previous version as quickly as possible in response to these complaints. What should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should set the previous version as default to route all traffic in App Engine Console. -&gt;&nbsp;Correct. Setting the previous version as default will immediately route all traffic back to the previous version of the application, which will effectively revert the application to the previous version. This can be done quickly and easily in the App Engine Console, without requiring any additional deployments or configuration changes.</p><p><br></p><p>You should deploy the previous version as a new App Engine Application and use traffic splitting feature to send all traffic to the new application. -&gt; Incorrect. It is not the best approach, as deploying the previous version as a new App Engine application and using traffic splitting would require more effort and resources than simply reverting to the previous version.</p><p><br></p><p>You should deploy the previous version in Flexible environment and use traffic splitting feature to send all traffic to the new application. -&gt; Incorrect. It is also not the best approach, as deploying the previous version in the Flexible environment would require additional configuration and maintenance compared to simply setting the previous version as the default.</p><p><br></p><p>You should deploy the previous version on a Kubernetes cluster and use traffic splitting feature to send all traffic to the new application. -&gt; Incorrect. It is not the best approach, as deploying the previous version on a Kubernetes cluster would also require additional configuration and maintenance compared to simply setting the previous version as the default. Additionally, using a Kubernetes cluster for this task may be overkill, as App Engine provides built-in functionality for managing multiple versions of an application.</p><p><br></p><p>https://cloud.google.com/appengine/docs/standard/python/tools/uploadinganapp</p>",
                "answers": [
                    "<p>You should set the previous version as default to route all traffic in App Engine Console.</p>",
                    "<p>You should deploy the previous version as a new App Engine Application and use traffic splitting feature to send all traffic to the new application.</p>",
                    "<p>You should deploy the previous version in Flexible environment and use traffic splitting feature to send all traffic to the new application.</p>",
                    "<p>You should deploy the previous version on a Kubernetes cluster and use traffic splitting feature to send all traffic to the new application.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "After adding a new version of your application in App Engine Standard, users have reported experiencing slow performance issues. Your immediate objective is to revert to the previous version as quickly as possible in response to these complaints. What should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163876,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A company wants to migrate on-premises data center to Google Cloud. As a cloud architect, you need to estimate monthly expenses that this company needs to run all their infrastructure in GCP. How can you calculate your expenses?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should use the Google Cloud Pricing Calculator to estimate the monthly expenses. -&gt; Correct. It is the correct answer because the Google Cloud Pricing Calculator allows you to estimate the cost of running all infrastructure on GCP, including the cost of computing, storage, networking, and other services that the company might require. The calculator provides you with a breakdown of the estimated costs for each service and allows you to adjust parameters to simulate various scenarios.</p><p><br></p><p>You should capture the pricing from the products pricing page and manually calculate monthly expenses. -&gt;&nbsp;Incorrect. While the pricing information is available on the products pricing page, manually calculating the monthly expenses based on this information can be challenging and time-consuming, especially when dealing with multiple services and configurations. The Google Cloud Pricing Calculator provides a more convenient and accurate estimation.</p><p><br></p><p>You should migrate all applications to GCP and run them for a week. Then based on that, calculate monthly expenses. -&gt;&nbsp;Incorrect. Migrating applications and running them for a week does not provide a reliable basis for calculating the monthly expenses. This approach does not consider the ongoing costs, such as storage, network usage, or other services required for the infrastructure. It is more suitable for testing and performance evaluation rather than cost estimation.</p><p><br></p><p>You should migrate all applications to GCP and run them for a day. Then based on that, calculate monthly expenses. -&gt;&nbsp;Incorrect. Migrating applications and running them for a day does not provide a reliable basis for calculating the monthly expenses. This approach does not consider the ongoing costs, such as storage, network usage, or other services required for the infrastructure. It is more suitable for testing and performance evaluation rather than cost estimation.</p><p><br></p><p>https://cloud.google.com/products/calculator</p>",
                "answers": [
                    "<p>You should use the Google Cloud Pricing Calculator to estimate the monthly expenses.</p>",
                    "<p>You should capture the pricing from the products pricing page and manually calculate monthly expenses.</p>",
                    "<p>You should migrate all applications to GCP and run them for a week. Then based on that, calculate monthly expenses.</p>",
                    "<p>You should migrate all applications to GCP and run them for a day. Then based on that, calculate monthly expenses.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A company wants to migrate on-premises data center to Google Cloud. As a cloud architect, you need to estimate monthly expenses that this company needs to run all their infrastructure in GCP. How can you calculate your expenses?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163878,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you are faced with the situation where you have recently deployed an application on a single Compute Engine virtual machine instance, but its popularity is not meeting your initial expectations. Your goal now is to minimize costs associated with this scenario. What would be the optimal deployment location for your application?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should containerize your application an deploy with Cloud Run. -&gt; Correct. Cloud Run allows you to run stateless containers that are automatically scaled up and down based on incoming requests, which can help minimize costs. With Cloud Run, you only pay for the resources you use, and there are no instances to manage or scaling decisions to make. This makes it an ideal option for applications that are not as popular as expected and need to be run cost-effectively.</p><p><br></p><p>You should deploy your application with App Engine Flexible. -&gt; Incorrect. App Engine Flexible is also good option for scalable applications, but it may be more complex to set up and manage compared to Cloud Run. Additionally, it may require more resources and have higher costs, which can be a disadvantage if you are trying to minimize costs.</p><p><br></p><p>You should deploy your application with Kubernetes Engine with horizontal pod autoscaling and cluster autoscaler enabled. -&gt; Incorrect. Kubernetes Engine is also good option for scalable applications, but it may be more complex to set up and manage compared to Cloud Run. Additionally, it&nbsp; may require more resources and have higher costs, which can be a disadvantage if you are trying to minimize costs.</p><p><br></p><p>In this case, it is not possible to reduce costs. -&gt; Incorrect. You can almost always cut costs by optimizing your infrastructure, choosing the right services, and making sure you only use the resources you need.</p><p><br></p><p>https://cloud.google.com/run/docs/quickstarts</p>",
                "answers": [
                    "<p>You should containerize your application an deploy with Cloud Run.</p>",
                    "<p>You should deploy your application with App Engine Flexible.</p>",
                    "<p>You should deploy your application with Kubernetes Engine with horizontal pod autoscaling and cluster autoscaler enabled.</p>",
                    "<p>In this case, it is not possible to reduce costs.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you are faced with the situation where you have recently deployed an application on a single Compute Engine virtual machine instance, but its popularity is not meeting your initial expectations. Your goal now is to minimize costs associated with this scenario. What would be the optimal deployment location for your application?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163880,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>An online marketing company has several critical applications running on its private data center. They want to use Compute Engine to handle traffic bursts and communicate via their internal IP addresses. What should you advise them?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should allow applications in the data center to scale to Google Cloud through the VPN tunnel. -&gt; Correct. By establishing a VPN tunnel between their private data center and GCP, the applications can scale out to Google Cloud during traffic bursts and communicate using their internal IP addresses. This satisfies the requirements without changing the current setup or introducing potential conflicts.</p><p><br></p><p>They should create a new VPC in GCP with an overlapping IP range and configure Cloud VPN between the private network and GCP. -&gt; Incorrect. Overlapping IP ranges can cause routing issues, and it's generally not recommended. Creating a VPC in GCP with an overlapping IP range would lead to IP conflicts and might render some systems unreachable.</p><p><br></p><p>They should create a new GCP project and a new VPC and make this a shared VPC with the private network. Then, allow applications in the data center to scale to Google Cloud on the shared VPC. -&gt; Incorrect. Shared VPCs in GCP are used to share networking resources across different GCP projects. The question doesn't suggest there's a need for multiple GCP projects, so this option adds unnecessary complexity.</p><p><br></p><p>They should migrate all applications from private data center to the Google Cloud. -&gt; Incorrect. This is a drastic move and isn't aligned with the scenario described. Migrating everything to Google Cloud might not be necessary if the company only wants to handle traffic bursts.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/vpn</p>",
                "answers": [
                    "<p>They should create a new VPC in GCP with an overlapping IP range and configure Cloud VPN between the private network and GCP.</p>",
                    "<p>They should allow applications in the data center to scale to Google Cloud through the VPN tunnel.</p>",
                    "<p>They should create a new GCP project and a new VPC and make this a shared VPC with the private network. Then, allow applications in the data center to scale to Google Cloud on the shared VPC.</p>",
                    "<p>They should migrate all applications from private data center to the Google Cloud.</p>"
                ]
            },
            "correct_response": [
                "b"
            ],
            "section": "",
            "question_plain": "An online marketing company has several critical applications running on its private data center. They want to use Compute Engine to handle traffic bursts and communicate via their internal IP addresses. What should you advise them?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163882,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A machine learning team needs to use a Kubernetes Engine cluster with specific GPUs to process long running jobs that cannot be restarted. In this case, how do you recommend configuring the Kubernetes Engine cluster?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should deploy the workload on a node pool with non-preemptible compute engine instances and GPUs attached. Enable cluster autoscaling and set min-nodes to 1. -&gt;&nbsp;Correct. The reason for choosing this option is that the requirement specifies that the long running jobs cannot be restarted, and preemptible instances can be shut down at any time, which can cause the loss of data and progress. Therefore, it is recommended to use non-preemptible instances to ensure the stability and reliability of the workload. Moreover, since the workload requires specific GPUs, the team should deploy the workload on a node pool with GPUs attached. Cluster autoscaling can be enabled to ensure that the workload can scale to meet demand, and setting min-nodes to 1 can ensure that there is always at least one node available for the workload to run on.</p><p><br></p><p>They should enable Vertical Pod autoscaling. -&gt;&nbsp;Incorrect. Enabling Vertical Pod autoscaling, is not relevant to the requirements specified in the question.</p><p><br></p><p>They should enable Kubernetes Engine cluster node auto-provisioning. -&gt;&nbsp;Incorrect. Enabling Kubernetes Engine cluster node auto-provisioning, can help automate the creation of new nodes when the workload demands it, but it does not address the requirement for specific GPUs and non-preemptible instances.</p><p><br></p><p>They should deploy the workload on a node pool with preemptible compute engine instances and GPUs attached. -&gt; Incorrect. Deploying the workload on a node pool with preemptible compute engine instances and GPUs attached, is not recommended as it can result in data and progress loss due to the nature of preemptible instances.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs</p>",
                "answers": [
                    "<p>They should deploy the workload on a node pool with non-preemptible compute engine instances and GPUs attached. Enable cluster autoscaling and set min-nodes to 1.</p>",
                    "<p>They should enable Vertical Pod autoscaling.</p>",
                    "<p>They should enable Kubernetes Engine cluster node auto-provisioning.</p>",
                    "<p>They should deploy the workload on a node pool with preemptible compute engine instances and GPUs attached.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A machine learning team needs to use a Kubernetes Engine cluster with specific GPUs to process long running jobs that cannot be restarted. In this case, how do you recommend configuring the Kubernetes Engine cluster?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163884,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, it is necessary for you to adhere to your organization's guidelines when utilizing Cloud Storage for the storage of company data. These guidelines dictate the archiving of data that is more than one year old and the deletion of data that is older than three years. What course of action should you take?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should set up Object Lifecycle Management policies. -&gt; Correct. Object Lifecycle Management policies are specifically designed to automate the process of archiving and deleting objects based on their age. With Object Lifecycle Management policies, the cloud architect can set up rules to automatically transition data to archival storage after a specified period of time and to automatically delete data after a specified period of time. This ensures compliance with the organization's regulations without the need for manual intervention.</p><p><br></p><p>You should run a script every day. Copy data that is older than one year to an archive bucket, and delete data from three years ago. -&gt; Incorrect. Running a script every day to copy or move data to an archive bucket can be error-prone and may require manual intervention if something goes wrong. Also, it does not provide the same level of automation and control that Object Lifecycle Management policies offer.</p><p><br></p><p>You should run a script every day. Set storage class to Archive for data that is older than one year, and delete data from three years ago. -&gt; Incorrect. Running a script every day to change the storage class to Archive, can be error-prone and may require manual intervention if something goes wrong. Also, it does not provide the same level of automation and control that Object Lifecycle Management policies offer.</p><p><br></p><p>You should set up default storage class for two buckets with storage classes: Standard and Archive. Use a script to move the data in the appropriate bucket when its needed. -&gt; Incorrect. Setting up default storage class for two buckets, does not provide the same level of automation and control as Object Lifecycle Management policies. It would require manual intervention to move the data to the appropriate bucket, which can be cumbersome and prone to errors.</p><p><br></p><p>https://cloud.google.com/storage/docs/lifecycle</p>",
                "answers": [
                    "<p>You should set up Object Lifecycle Management policies.</p>",
                    "<p>You should run a script every day. Copy data that is older than one year to an archive bucket, and delete data from three years ago.</p>",
                    "<p>You should run a script every day. Set storage class to Archive for data that is older than one year, and delete data from three years ago.</p>",
                    "<p>You should set up default storage class for two buckets with storage classes: Standard and Archive. Use a script to move the data in the appropriate bucket when its needed.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, it is necessary for you to adhere to your organization's guidelines when utilizing Cloud Storage for the storage of company data. These guidelines dictate the archiving of data that is more than one year old and the deletion of data that is older than three years. What course of action should you take?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163886,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you need to prepare a resource hierarchy for your company. Suppose your company has two different applications with development and production environment. With Google's best practices in mind, what should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should create four different projects (for each application and environment). This isolates the environments from each other, so changes to the development project don't accidently impact production environment. This also gives you better access control. -&gt; Correct. Google's best practice recommends using multiple projects, one for each environment and application, to isolate environments from each other, give better access control, and avoid changes to the development project accidentally impacting the production environment. Creating four different projects (for each application and environment) is the most effective way to achieve this. This also allows for better resource management, as each project has its own set of quotas, billing, and monitoring.</p><p><br></p><p>You should create all applications in one project. -&gt; Incorrect. Creating all applications in one project might result in resource sharing between development and production environments, increasing the risk of accidents or unintended changes. </p><p><br></p><p>You should create two projects, each for one application. -&gt;&nbsp;Incorrect. Creating two projects, each for one application, does not provide the needed separation of development and production environments. </p><p><br></p><p>You should create two projects, each for one environment. -&gt; Incorrect. Creating two projects, each for one environment, does not separate applications and may make resource management more challenging.</p><p><br></p><p>https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#project-structure</p>",
                "answers": [
                    "<p>You should create four different projects (for each application and environment). This isolates the environments from each other, so changes to the development project don't accidently impact production environment. This also gives you better access control.</p>",
                    "<p>You should create all applications in one project.</p>",
                    "<p>You should create two projects, each for one application.</p>",
                    "<p>You should create two projects, each for one environment.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you need to prepare a resource hierarchy for your company. Suppose your company has two different applications with development and production environment. With Google's best practices in mind, what should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163888,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You provide a service that you need to open to everyone in your partner network and have a server and an IP address where the application is located. You do not want to have to change the IP address on your DNS server if your server goes down or is replaced. You also want to avoid downtime and deliver a solution with minimal cost and setup. What should you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should reserve a static external IP address, and assign it using Cloud DNS. -&gt; Correct.&nbsp; Reserving a static external IP address and assigning it using Cloud DNS can provide a stable IP address to your application and can eliminate the need for changing the IP address on your DNS server if your server goes down or is replaced. This solution can also avoid downtime and deliver a solution with minimal cost and setup. </p><p><br></p><p>You should create a script that updates the domain's IP address when the server goes down or is replaced. -&gt; Incorrect. Using a script to update the domain's IP address when the server goes down or is replaced may not be reliable and can lead to downtime. </p><p><br></p><p>You should reserve a static internal IP address, and assign it using Cloud DNS. -&gt; Incorrect. Reserving a static internal IP address may not be sufficient if you need to expose your service to the partner network. </p><p><br></p><p>You should use the Bring Your Own IP (BYOIP) method to use your own IP address. -&gt; Incorrect. Using Bring Your Own IP (BYOIP) method may require significant setup and configuration and may not be the most cost-effective solution.</p><p><br></p><p>https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address</p>",
                "answers": [
                    "<p>You should reserve a static external IP address, and assign it using Cloud DNS.</p>",
                    "<p>You should create a script that updates the domain's IP address when the server goes down or is replaced.</p>",
                    "<p>You should reserve a static internal IP address, and assign it using Cloud DNS.</p>",
                    "<p>You should use the Bring Your Own IP (BYOIP) method to use your own IP address.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You provide a service that you need to open to everyone in your partner network and have a server and an IP address where the application is located. You do not want to have to change the IP address on your DNS server if your server goes down or is replaced. You also want to avoid downtime and deliver a solution with minimal cost and setup. What should you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163890,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your team needs to create development, test and production environments for project in Google Cloud. As a cloud architect, you need to effectively implement and manage these environments and ensure their consistency. With Google's best practices in mind, what should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should use the Cloud Foundation Toolkit to create a single deployment template that will work for all environments, and deploy with Terraform. -&gt; Correct. The Cloud Foundation Toolkit provides a set of best practices, tools, and templates that help you implement consistent and repeatable infrastructure in Google Cloud. Using a single deployment template for all environments will ensure consistency and reduce errors. Deploying with Terraform is a good option as well, as it allows for infrastructure as code and version control.</p><p><br></p><p>You should create a Cloud Shell script that uses <code>gcloud</code> commands to deploy the environments. -&gt; Incorrect. It may work for small deployments but can be difficult to maintain and scale.</p><p><br></p><p>You should create a single Terraform configuration for all environments. -&gt; Incorrect. It can be challenging to maintain and update as it may require significant changes to accommodate differences between environments.</p><p><br></p><p>You should create a Terraform configuration for each environment. Use them for repeated deployment. -&gt; Incorrect. It can be a good option if there are significant differences between environments that require unique configuration. However, this can lead to inconsistency between environments if changes are not consistently applied to all configurations.</p><p><br></p><p>https://cloud.google.com/foundation-toolkit</p>",
                "answers": [
                    "<p>You should use the Cloud Foundation Toolkit to create a single deployment template that will work for all environments, and deploy with Terraform.</p>",
                    "<p>You should create a Cloud Shell script that uses <code>gcloud</code> commands to deploy the environments.</p>",
                    "<p>You should create a single Terraform configuration for all environments.</p>",
                    "<p>You should create a Terraform configuration for each environment. Use them for repeated deployment.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your team needs to create development, test and production environments for project in Google Cloud. As a cloud architect, you need to effectively implement and manage these environments and ensure their consistency. With Google's best practices in mind, what should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163892,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your company is running several related applications on Compute Engine virtual machine instances and wants to expose each application through a DNS name. With Google's best practices in mind, what should you recommend to them?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should use Cloud DNS to translate their domain names into IP addresses. -&gt; Correct. Cloud DNS is a scalable, reliable, and managed authoritative Domain Name System (DNS) service that allows you to easily publish and manage domain names to the internet. It translates human-readable domain names into the numeric IP addresses that computers use to connect to each other. Therefore, this is the standard and recommended way to expose applications on Compute Engine instances through DNS names, following Google's best practices.</p><p><br></p><p>They should assign Google Cloud routes to their virtual machines, assign DNS names to routes, and make the DNS names public. -&gt;&nbsp;Incorrect. Routes are not meant to be exposed to the internet. Instead, they define paths network traffic takes from a VM instance to other networks. They don't have direct relation with DNS.</p><p><br></p><p>They should assign an alias IP address range to each virtual machine, and then make the internal DNS names public. -&gt;&nbsp;Incorrect. Assigning an alias IP address range to each VM and making the internal DNS names public would not be a standard or recommended way to expose applications.</p><p><br></p><p>They should use Compute Engine's internal DNS service to assign DNS names to virtual machines and make them available to users. -&gt;&nbsp;Incorrect. Compute Engine's internal DNS service is primarily meant for internal communications within a network, not for exposing applications on the internet. This service enables instances to resolve the hostnames of other instances within the same network.</p><p><br></p><p>https://cloud.google.com/dns/docs</p>",
                "answers": [
                    "<p>They should use Cloud DNS to translate their domain names into IP addresses.</p>",
                    "<p>They should assign Google Cloud routes to their virtual machines, assign DNS names to routes, and make the DNS names public.</p>",
                    "<p>They should assign an alias IP address range to each virtual machine, and then make the internal DNS names public.</p>",
                    "<p>They should use Compute Engine's internal DNS service to assign DNS names to virtual machines and make them available to users.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your company is running several related applications on Compute Engine virtual machine instances and wants to expose each application through a DNS name. With Google's best practices in mind, what should you recommend to them?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163894,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your organization stores sensitive customer data in Cloud Storage. You have been asked to design a solution that both prevents unauthorized data access and ensures regulatory compliance. Which of the following approaches would be the most appropriate?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Encrypt data using customer-managed encryption keys (CMEK) and enforce fine-grained access control with Identity and Access Management (IAM). -&gt;&nbsp;Correct. By using CMEK, you can control the encryption and decryption keys. With IAM, you can enforce fine-grained access control, ensuring that only authorized entities have access to specific resources.</p><p><br></p><p>Implement Cloud Identity-Aware Proxy (IAP) to control access to Cloud Storage. -&gt;&nbsp;Incorrect. While IAP is an effective tool for controlling access to applications deployed on Google Cloud, it's not specifically designed to secure data stored in Cloud Storage.</p><p><br></p><p>Use VPC Service Controls to isolate Cloud Storage. -&gt;&nbsp;Incorrect. While VPC Service Controls can provide additional security measures, they are primarily used for preventing data exfiltration from Google Cloud services. They do not directly handle encryption or access management within Cloud Storage.</p><p><br></p><p>Use Cloud Audit Logs to monitor access to Cloud Storage. -&gt;&nbsp;Incorrect. While Cloud Audit Logs can provide valuable information on who did what, when, and where, they are more about visibility and accountability, and do not prevent unauthorized access to Cloud Storage.</p>",
                "answers": [
                    "<p>Encrypt data using customer-managed encryption keys (CMEK) and enforce fine-grained access control with Identity and Access Management (IAM).</p>",
                    "<p>Implement Cloud Identity-Aware Proxy (IAP) to control access to Cloud Storage.</p>",
                    "<p>Use VPC Service Controls to isolate Cloud Storage.</p>",
                    "<p>Use Cloud Audit Logs to monitor access to Cloud Storage.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your organization stores sensitive customer data in Cloud Storage. You have been asked to design a solution that both prevents unauthorized data access and ensures regulatory compliance. Which of the following approaches would be the most appropriate?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163896,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are planning to make your API publicly available and you have concerns about potential DDoS attacks targeting your service. Which GCP service should be taken into consideration to ensure the protection of your API?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Cloud Armor -&gt; Correct. Cloud Armor is a service provided by Google Cloud Platform (GCP) that offers security policies and defenses against distributed denial-of-service (DDoS) attacks. It allows you to define and enforce granular rules to control and filter incoming traffic to your API. With Cloud Armor, you can set up rules to block or allow traffic based on various parameters, such as IP addresses, geographical locations, or specific HTTP headers.</p><p><br></p><p>Cloud IAM -&gt; Incorrect. Cloud IAM (Identity and Access Management) is a service that manages access control and permissions for resources within GCP. While it is essential for managing and controlling user access to your GCP resources, it does not specifically address the protection of your API from DDoS attacks.</p><p><br></p><p>Cloud CDN -&gt; Incorrect. Cloud CDN (Content Delivery Network) is a service that caches and delivers content from Google's global network of edge locations. While Cloud CDN can improve the performance and latency of your API by caching and serving content closer to your users, it does not provide specific protections against DDoS attacks.</p><p> </p><p>Cloud VPN -&gt; Incorrect. Cloud VPN is a service that enables secure connections between your on-premises network and your GCP virtual private cloud (VPC) network. While it establishes a secure connection, it is primarily used for secure network connectivity rather than protecting your API from DDoS attacks.</p><p><br></p><p>https://cloud.google.com/armor/docs/cloud-armor-overview</p>",
                "answers": [
                    "<p>Cloud Armor</p>",
                    "<p>Cloud IAM</p>",
                    "<p>Cloud CDN</p>",
                    "<p>Cloud VPN</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are planning to make your API publicly available and you have concerns about potential DDoS attacks targeting your service. Which GCP service should be taken into consideration to ensure the protection of your API?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163898,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are the lead cloud architect for a multinational firm which plans to deploy its complex microservices-based applications to the Google Cloud Platform (GCP). The firm has an SLA of 99.99% uptime and your application should be available all the time. The application also has varying loads throughout the day and spikes during the holiday season. Which is the most effective solution?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Deploy the application on Kubernetes Engine (GKE) with clusters in multiple regions and with autoscaling enabled. -&gt;&nbsp;Correct. Kubernetes provides a great platform for deploying and managing complex microservices-based applications. Autoscaling will handle varying loads, and multi-region clusters provide the redundancy necessary to meet the firm's high uptime SLA.</p><p><br></p><p>Deploy the application on Compute Engine instances within a single region. -&gt;&nbsp;Incorrect. This approach doesn't account for regional outages and doesn't automatically scale according to the load. It's unlikely to meet the firm's uptime SLA.</p><p><br></p><p>Deploy the application on App Engine Standard with autoscaling enabled. -&gt;&nbsp;Incorrect. While App Engine Standard can auto-scale and meet high load requirements, it's less suited for complex microservices-based applications. It also doesn't inherently provide multi-region redundancy.</p><p><br></p><p>Deploy the application on a combination of Compute Engine instances and Cloud Functions. -&gt;&nbsp;Incorrect. This combined approach is not optimal for managing complex microservices-based applications and does not provide automatic scaling or multi-region redundancy inherently.</p>",
                "answers": [
                    "<p>Deploy the application on Kubernetes Engine (GKE) with clusters in multiple regions and with autoscaling enabled.</p>",
                    "<p>Deploy the application on Compute Engine instances within a single region.</p>",
                    "<p>Deploy the application on App Engine Standard with autoscaling enabled.</p>",
                    "<p>Deploy the application on a combination of Compute Engine instances and Cloud Functions.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are the lead cloud architect for a multinational firm which plans to deploy its complex microservices-based applications to the Google Cloud Platform (GCP). The firm has an SLA of 99.99% uptime and your application should be available all the time. The application also has varying loads throughout the day and spikes during the holiday season. Which is the most effective solution?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163900,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>One of your web application is becoming widely used. The frontend runs in App Engine and scales automatically. The backend runs in a Managed Instance Group on Compute Engine with the maximum number of instances set to 10. Sometimes the frontend sends more data than the backend can keep up and the data is lost, but you do not want to increase the maximum size of the MIG or change the VM instance type. As a cloud architect, what can you recommend to prevent data loss?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should have the frontend writing data to the Cloud Pub/Sub topic, and the backend read from that topic. This provide a managed and scalable message queue, and stores ingested data until the backend can process it. -&gt; Correct. You should have the frontend writing data to the Cloud Pub/Sub topic, and the backend read from that topic. This provides a managed and scalable message queue, and stores ingested data until the backend can process it. When the frontend sends more data than the backend can handle, data is lost, and this is an issue. Cloud Pub/Sub is a messaging service that decouples senders and receivers of messages. Therefore, using Cloud Pub/Sub as a message queue ensures that the frontend can send data to a buffer that stores ingested data until the backend can process it, preventing data loss. Additionally, Cloud Pub/Sub is highly scalable and can handle large volumes of messages, making it a perfect solution for a widely used web application.</p><p><br></p><p>You should use an unmanaged instance group. -&gt; Incorrect. It is not a solution for the data loss problem. </p><p><br></p><p>You should store ingested data in Cloud Storage. -&gt; Incorrect. It does not provide a message queue or buffer to store ingested data until the backend can process it, so data loss is still possible.</p><p><br></p><p>You should store ingested data in BigQuery. -&gt; Incorrect. It does not provide a message queue or buffer to store ingested data until the backend can process it, so data loss is still possible.</p><p><br></p><p>https://cloud.google.com/pubsub/docs/create-topic-console</p>",
                "answers": [
                    "<p>You should have the frontend writing data to the Cloud Pub/Sub topic, and the backend read from that topic. This provide a managed and scalable message queue, and stores ingested data until the backend can process it.</p>",
                    "<p>You should use an unmanaged instance group.</p>",
                    "<p>You should store ingested data in Cloud Storage.</p>",
                    "<p>You should store ingested data in BigQuery.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "One of your web application is becoming widely used. The frontend runs in App Engine and scales automatically. The backend runs in a Managed Instance Group on Compute Engine with the maximum number of instances set to 10. Sometimes the frontend sends more data than the backend can keep up and the data is lost, but you do not want to increase the maximum size of the MIG or change the VM instance type. As a cloud architect, what can you recommend to prevent data loss?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163902,
            "assessment_type": "multi-select",
            "prompt": {
                "question": "<p>As a cloud architect, your task is to transfer all on-premises workloads to Google Cloud. Specifically, you are interested in running a custom container within a managed service. What are the available options for you to consider?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>App Engine Flexible -&gt;&nbsp;Correct. It is a fully managed platform that allows you to build and run containerized applications. It supports a wide range of languages, including Java, Python, Node.js, and Go. App Engine Flexible is a good choice when you need to deploy and run your custom container in a fully managed environment with automatic scaling, load balancing, and monitoring.</p><p><br></p><p>Kubernetes Engine -&gt; Correct. It is a managed service for running containerized applications using Kubernetes. It allows you to create and manage Kubernetes clusters, and deploy and manage containers in a highly available and scalable environment. Kubernetes Engine is a good choice when you need a more flexible container environment, with advanced features such as automatic scaling, rolling updates, and load balancing.</p><p><br></p><p>App Engine Standard -&gt;&nbsp;Incorrect. App Engine Standard Environment is a platform-as-a-service (PaaS) offering on Google Cloud, but it does not support running custom containers. It provides a runtime environment for specific programming languages (such as Python, Java, Go, etc.) and imposes some restrictions on the application architecture and dependencies.</p><p><br></p><p>Compute Engine -&gt;&nbsp;Incorrect. Compute Engine is an infrastructure-as-a-service (IaaS) offering on Google Cloud that allows you to create and manage virtual machines (VMs). While you can run containers within VMs on Compute Engine, it does not provide a managed service specifically designed for running containers like the other options mentioned.</p><p><br></p><p>Cloud Functions -&gt;&nbsp;Incorrect. Cloud Functions is a serverless compute platform that enables you to run code in response to events. It is designed for small, event-driven functions and does not directly support running custom containers.</p><p><br></p><p>https://cloud.google.com/appengine/docs/flexible</p><p>https://cloud.google.com/kubernetes-engine/docs/quickstart</p>",
                "answers": [
                    "<p>App Engine Flexible</p>",
                    "<p>Kubernetes Engine</p>",
                    "<p>App Engine Standard</p>",
                    "<p>Compute Engine</p>",
                    "<p>Cloud Functions</p>"
                ]
            },
            "correct_response": [
                "a",
                "b"
            ],
            "section": "",
            "question_plain": "As a cloud architect, your task is to transfer all on-premises workloads to Google Cloud. Specifically, you are interested in running a custom container within a managed service. What are the available options for you to consider?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163904,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you aim to enhance the processing speed of a web application that generates thumbnails from user-uploaded photos. Currently, the frontend application uploads photos to Cloud Storage, while the outdated backend relies on a cron job that checks Cloud Storage buckets every 20 minutes for new photos. Your objective is to optimize this application and process the photos as soon as possible. Which Google Cloud service would be the most suitable choice?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Cloud Function -&gt;&nbsp;Correct. Cloud Functions allow you to execute code in response to events, such as an uploaded photo to Cloud Storage. With Cloud Functions, you can trigger the thumbnail generation process immediately after a photo is uploaded, resulting in faster processing speed compared to the current cron job approach.</p><p><br></p><p>App Engine Flexible -&gt;&nbsp;Incorrect. App Engine Flexible is a platform-as-a-service (PaaS) offering that allows you to deploy and manage applications, but it may not provide the necessary event-driven capabilities for immediate processing of uploaded photos.</p><p><br></p><p>Kubernetes pod -&gt;&nbsp;Incorrect. Kubernetes pods are a fundamental unit of deployment in Kubernetes clusters, but they do not inherently provide event-driven functionality for processing uploaded photos in real-time.</p><p><br></p><p>A cron job that checks the bucket more often. -&gt;&nbsp;Incorrect. Increasing the frequency of the cron job to check the bucket more often reduces the delay between checks, but it still relies on periodic checks rather than immediate processing triggered by events.</p><p><br></p><p>https://cloud.google.com/functions/docs/how-to</p>",
                "answers": [
                    "<p>Cloud Function</p>",
                    "<p>App Engine Flexible</p>",
                    "<p>Kubernetes pod</p>",
                    "<p>A cron job that checks the bucket more often.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you aim to enhance the processing speed of a web application that generates thumbnails from user-uploaded photos. Currently, the frontend application uploads photos to Cloud Storage, while the outdated backend relies on a cron job that checks Cloud Storage buckets every 20 minutes for new photos. Your objective is to optimize this application and process the photos as soon as possible. Which Google Cloud service would be the most suitable choice?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163906,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>An online marketing company wants to migrate a local data warehouse to GCP and they want to use a managed cloud solution. As a cloud architect, you advise them which service they should use. What do you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>BigQuery -&gt; Correct. BigQuery is Google Cloud's fully managed, petabyte-scale, and cost-effective analytics data warehouse that lets you run analytics over vast amounts of data in near real time. With BigQuery, there's no infrastructure to set up or manage, letting you focus on finding meaningful insights using standard SQL and taking advantage of flexible pricing models across on-demand and flat-rate options.</p><p><br></p><p>Compute Engine -&gt; Incorrect. Compute Engine isn't a managed service. </p><p><br></p><p>Cloud Dataproc -&gt; Incorrect. Dataproc is a managed Hadoop and Spark service.</p><p><br></p><p>Cloud Bigtable -&gt;&nbsp;Incorrect. Bigtable is a NoSQL database for low-latency writes and limited ranges of queries. </p><p><br></p><p>Cloud Storage -&gt; Incorrect. Cloud Storage isn't a good choice for data warehouse (object storage).</p><p><br></p><p>https://cloud.google.com/bigquery/docs/introduction</p>",
                "answers": [
                    "<p>BigQuery</p>",
                    "<p>Compute Engine</p>",
                    "<p>Cloud Dataproc</p>",
                    "<p>Cloud Bigtable</p>",
                    "<p>Cloud Storage</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "An online marketing company wants to migrate a local data warehouse to GCP and they want to use a managed cloud solution. As a cloud architect, you advise them which service they should use. What do you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163908,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, it is your duty to oversee the expansion of a web application from North America to Europe. This web application collects Personally Identifiable Information (PII). What regulations must you bear in mind when entering the European market?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>GDPR - General Data Protection Regulation -&gt; Correct.&nbsp; The GDPR is a regulation that protects the privacy and personal data of individuals residing in the European Union (EU). It applies to all businesses that collect or process personal data of EU residents, regardless of whether the business is based within the EU or not. Therefore, as a cloud architect expanding a web application from North America to Europe and collecting Personally Identifiable Information (PII), you must comply with GDPR regulations.</p><p><br></p><p>PCI&nbsp;DSS - Payment Card Industry Data Security Standard -&gt; Incorrect. PCI DSS is a set of security standards designed to protect credit card information during transactions. It does not apply to PII in general.</p><p><br></p><p>HIPAA - Health Insurance Portability &amp; Accountability Act -&gt; Incorrect. HIPAA is a US regulation that sets the standards for the protection of health information. It does not apply to PII in general.</p><p><br></p><p>SOX - Sarbanes-Oxley Act -&gt; Incorrect. SOX is a US regulation that sets the standards for financial reporting and accountability. It does not apply to PII in general.</p><p><br></p><p>https://cloud.google.com/privacy/gdpr</p>",
                "answers": [
                    "<p>GDPR - General Data Protection Regulation</p>",
                    "<p>PCI&nbsp;DSS - Payment Card Industry Data Security Standard</p>",
                    "<p>HIPAA - Health Insurance Portability &amp; Accountability Act</p>",
                    "<p>SOX - Sarbanes-Oxley Act</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, it is your duty to oversee the expansion of a web application from North America to Europe. This web application collects Personally Identifiable Information (PII). What regulations must you bear in mind when entering the European market?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163910,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A small mobile gaming company wants to benefit from cloud solutions and migrate mobile game application that uses PostgreSQL database to Google Cloud. They have a small development team and want to minimize administrative tasks. What managed service do you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Cloud SQL -&gt; Correct. Cloud SQL is a fully managed relational database service that automates administrative tasks such as database provisioning, patching, and backups, which can help minimize the administrative tasks for the small development team. Additionally, Cloud SQL supports PostgreSQL, which is the database currently being used by the mobile gaming company. </p><p><br></p><p>Cloud Spanner -&gt;&nbsp;Incorrect. It is a globally distributed, horizontally scalable, and strongly consistent database service that is best suited for mission-critical and complex applications. </p><p><br></p><p>Cloud Dataproc -&gt; Incorrect. It is a managed Spark and Hadoop service for processing large datasets. </p><p><br></p><p>Cloud Bigtable -&gt;&nbsp;Incorrect. It is a NoSQL database service that is best suited for large-scale and low-latency workloads.</p><p><br></p><p>https://cloud.google.com/sql/docs/postgres</p>",
                "answers": [
                    "<p>Cloud SQL</p>",
                    "<p>Cloud Spanner</p>",
                    "<p>Cloud Dataproc</p>",
                    "<p>Cloud Bigtable</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A small mobile gaming company wants to benefit from cloud solutions and migrate mobile game application that uses PostgreSQL database to Google Cloud. They have a small development team and want to minimize administrative tasks. What managed service do you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163912,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A healthcare company collects Personally Identifiable Information (PII) and they want to run a highly secure environment in Google Cloud. They want to use virtual machines to run workloads.&nbsp;What should you advise them?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should use Shielded VMs that only runs digitally verified boot components. -&gt; Correct. The healthcare company collects Personally Identifiable Information (PII), and therefore, as a cloud architect, you should advise them to use Shielded VMs that only run digitally verified boot components. Shielded VMs provide verifiable integrity, which means that it ensures that the VM boots from a known, verified, and trusted state. Shielded VMs provide the necessary secure boot process by using UEFI firmware, which confirms the signature of the boot loader before booting it. Shielded VMs also protect VMs against rootkit and bootkit malware attacks.</p><p><br></p><p>They should use Managed Instance Group. -&gt; Incorrect. Managed Instance Groups (MIGs) is a tool that helps you manage a group of virtual machine instances. It doesn't provide the same level of security as Shielded VMs.</p><p><br></p><p>They should use Cloud Functions. -&gt; Incorrect. Cloud Functions is a serverless computing solution where you write and deploy small code snippets that run in response to events.</p><p><br></p><p>They should use Preemptible VMs. -&gt; Incorrect. Preemptible VMs is a type of VM that you can use for short-lived, fault-tolerant workloads. Preemptible VMs have a lower price but can be stopped by Google at any time, which may not be suitable for highly secure environments.</p><p><br></p><p>https://cloud.google.com/compute/shielded-vm/docs/shielded-vm</p>",
                "answers": [
                    "<p>They should use Shielded VMs that only runs digitally verified boot components.</p>",
                    "<p>They should use Managed Instance Group.</p>",
                    "<p>They should use Cloud Functions.</p>",
                    "<p>They should use Preemptible VMs.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A healthcare company collects Personally Identifiable Information (PII) and they want to run a highly secure environment in Google Cloud. They want to use virtual machines to run workloads.&nbsp;What should you advise them?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163918,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you need to establish a connection between two Virtual Private Cloud networks that uses private IP address space. Traffic stays within Google's network and doesn't traverse the public internet. Which option should you choose?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>VPC&nbsp;Network Peering -&gt; Correct. VPC Network Peering is a service that enables you to establish a direct, private connection between two VPC networks. When you use VPC Network Peering, traffic stays within Google's network and doesn't traverse the public internet. Additionally, VPC Network Peering allows you to use private IP addresses within your VPC networks, which is what is needed in this scenario.</p><p><br></p><p>Custom subnets -&gt; Incorrect. It is not a valid option for establishing a connection between two VPC networks. Custom subnets are simply a way to divide a VPC network's IP address space into smaller subnets.</p><p><br></p><p>Firewall rules -&gt; Incorrect. It is a security feature that controls traffic to and from instances in a VPC network, but it doesn't establish a connection between two VPC networks.</p><p><br></p><p>Cloud Interconnect -&gt; Incorrect. It is used to connect your on-premises network to your Google Cloud VPC network using a physical connection, and it doesn't apply to this scenario where the connection needs to be established between two VPC networks.</p><p><br></p><p>Cloud VPN -&gt; Incorrect. It is used to connect your on-premises network to your Google Cloud VPC network using an IPsec VPN connection, and it doesn't apply to this scenario where the connection needs to be established between two VPC networks.</p><p><br></p><p>https://cloud.google.com/vpc/docs/vpc-peering</p>",
                "answers": [
                    "<p>VPC&nbsp;Network Peering</p>",
                    "<p>Custom subnets</p>",
                    "<p>Firewall rules</p>",
                    "<p>Cloud Interconnect</p>",
                    "<p>Cloud VPN</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you need to establish a connection between two Virtual Private Cloud networks that uses private IP address space. Traffic stays within Google's network and doesn't traverse the public internet. Which option should you choose?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163920,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>The stock market news application, which includes static content, is experiencing growing popularity. With users from various parts of the world, the application offers subscription plans. However, there is concern among the managers that extended page load times might lead to an increase in the churn rate. As a cloud architect, what recommendations should you provide in this situation?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>They should use Cloud CDN, which distributes static content globally. -&gt; Correct. The application is becoming more popular, and it has users all over the world. As a result, serving static content globally using a CDN (Content Delivery Network) can significantly reduce page load times, improving the user experience and reducing the churn rate. Cloud CDN is Google's solution for a global CDN, and it can cache content closer to the user, reducing the latency and improving the performance. Therefore, recommending Cloud CDN is a suitable solution for this scenario. </p><p><br></p><p>They should use Regional Cloud Storage. -&gt;&nbsp;Incorrect. Regional Cloud Storage is a storage option provided by Google Cloud, but it does not directly address the concern of extended page load times. Regional Cloud Storage may help with storing and retrieving data, but it does not provide the global distribution and caching capabilities that Cloud CDN offers.</p><p><br></p><p>They should use Cloud VPN. -&gt;&nbsp;Incorrect. Cloud VPN is a service that enables secure connections between your on-premises network and your Google Cloud virtual private network (VPC) network. While secure connectivity is important, it does not directly address the concern of page load times and user experience.</p><p><br></p><p>They should use Managed Instance Group. -&gt;&nbsp;Incorrect. Managed Instance Group is a feature in Google Cloud that allows you to manage a group of virtual machine instances. While it can help with scaling and managing instances, it does not specifically address the concern of extended page load times and improving user experience caused by latency.</p><p><br></p><p>https://cloud.google.com/cdn/docs/overview</p>",
                "answers": [
                    "<p>They should use Cloud CDN, which distributes static content globally.</p>",
                    "<p>They should use Regional Cloud Storage.</p>",
                    "<p>They should use Cloud VPN.</p>",
                    "<p>They should use Managed Instance Group.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "The stock market news application, which includes static content, is experiencing growing popularity. With users from various parts of the world, the application offers subscription plans. However, there is concern among the managers that extended page load times might lead to an increase in the churn rate. As a cloud architect, what recommendations should you provide in this situation?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163922,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>An insurance company uses several third-party enterprise applications that require special licenses. This company wants to migrate all workload to Google Cloud. As a cloud architect what should you check first?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should check if the licenses are transferable to the cloud. -&gt;&nbsp;Correct. Before migrating enterprise applications to the cloud, it is crucial to check whether the licenses for those applications are transferable. Some software licenses have restrictions or limitations that may prevent their use in a cloud environment. By checking the license terms and consulting with the software vendors, you can ensure compliance and avoid any licensing issues during the migration process.</p><p><br></p><p>You should check the cost of such a migration using Cloud Pricing Calculator. -&gt;&nbsp;Incorrect. While it is important to consider the cost implications of the migration, checking the license transferability should be prioritized before estimating the migration costs. The cost of the migration can be assessed after confirming that the licenses are transferable.</p><p><br></p><p>You don't need to check if your licenses are transferable to the cloud. Everything is open source in the cloud. -&gt;&nbsp;Incorrect. While the cloud offers a wide range of open-source solutions, not all enterprise applications are open source. It is essential to verify the license transferability for third-party applications before migrating them to the cloud.</p><p><br></p><p>You should go straight to migration process. -&gt;&nbsp;Incorrect. Jumping directly into the migration process without verifying the license transferability could lead to complications and non-compliance issues. It is necessary to assess the license terms and ensure they allow for the migration to the cloud.</p><p><br></p><p>https://cloud.google.com/compute/docs/nodes/bringing-your-own-licenses</p>",
                "answers": [
                    "<p>You should check if the licenses are transferable to the cloud.</p>",
                    "<p>You should check the cost of such a migration using Cloud Pricing Calculator.</p>",
                    "<p>You don't need to check if your licenses are transferable to the cloud. Everything is open source in the cloud.</p>",
                    "<p>You should go straight to migration process.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "An insurance company uses several third-party enterprise applications that require special licenses. This company wants to migrate all workload to Google Cloud. As a cloud architect what should you check first?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163924,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you are responsible for preparing a cloud migration plan for services that include wide range of data. A company has 10 PB of different data in on-premises data center. This data need to be transferred to Cloud Storage and the network bandwidth between the on-premises data center and Google Cloud is 10 Gbps. What transfer option should you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Transfer Appliance -&gt;&nbsp;Correct. Transfer Appliance is a high-capacity storage server that you can use to securely migrate your on-premises data to Google Cloud. It enables you to transfer large amounts of data quickly and easily, without being limited by your network bandwidth or data transfer costs.</p><p><br></p><p><code>gcloud</code> -&gt; Incorrect. <code>gcloud</code> is a command-line tool for managing Google Cloud resources, but it does not directly address the large-scale data transfer requirements for this scenario.</p><p><br></p><p><code>gsutil</code> -&gt; Incorrect. <code>gsutil</code> is acommand-line tool for managing data, but it does not directly address the large-scale data transfer requirements for this scenario.</p><p><br></p><p>BigQuery Data Transfer -&gt; Incorrect. BigQuery Data Transfer is a specialized service for transferring data into BigQuery, which is not relevant to this scenario.</p><p><br></p><p>Transfer Service -&gt; Incorrect. Transfer Service is a more general data transfer service for moving data into Google Cloud, but Transfer Appliance is better suited for this particular use case because of the large amount of data that needs to be transferred.</p><p><br></p><p>https://cloud.google.com/transfer-appliance/docs/4.0/overview</p>",
                "answers": [
                    "<p>Transfer Appliance</p>",
                    "<p><code>gcloud</code> </p>",
                    "<p><code>gsutil</code> </p>",
                    "<p>BigQuery Data Transfer</p>",
                    "<p>Transfer Service</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you are responsible for preparing a cloud migration plan for services that include wide range of data. A company has 10 PB of different data in on-premises data center. This data need to be transferred to Cloud Storage and the network bandwidth between the on-premises data center and Google Cloud is 10 Gbps. What transfer option should you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163926,
            "assessment_type": "multi-select",
            "prompt": {
                "question": "<p>A company is moving an enterprise application to the Google Cloud. This application runs on a cluster of virtual machines on private data center, and workloads are distributed by a load balancer. Select all true statements. (select 2)</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>The migration team decided not to make unnecessary changes before moving this application to the cloud. This migration strategy is called Lift and Shift. -&gt;&nbsp;Correct. Lift and Shift is a migration strategy where the company moves the existing workload to the cloud without making any significant changes. This is typically done when the workload is running on virtual machines on-premises and the company wants to take advantage of the cloud's benefits, such as scalability and availability.</p><p><br></p><p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Improve and Move. -&gt;&nbsp;Correct. Improve and Move is a migration strategy where the company optimizes the workload before moving it to the cloud. In this case, the migration team decided to use containers and Kubernetes Engine, which would involve making significant changes to the application architecture.</p><p><br></p><p>The migration team decided not to make unnecessary changes before moving this application to the cloud. This migration strategy is called Improve and Move. -&gt; Incorrect. It describes the Lift and Shift strategy.</p><p><br></p><p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Lift and Shift. -&gt;&nbsp;Incorrect. It describes the Improve and Move strategy.</p><p><br></p><p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Remove and Replace. -&gt;&nbsp;Incorrect. It describes a migration strategy that is not relevant to the scenario described in the question.</p><p><br></p><p>https://cloud.google.com/architecture/migration-to-gcp-getting-started#lift_and_shift</p><p>https://cloud.google.com/architecture/migration-to-gcp-getting-started#improve_and_move</p>",
                "answers": [
                    "<p>The migration team decided not to make unnecessary changes before moving this application to the cloud. This migration strategy is called Lift and Shift.</p>",
                    "<p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Improve and Move.</p>",
                    "<p>The migration team decided not to make unnecessary changes before moving this application to the cloud. This migration strategy is called Improve and Move.</p>",
                    "<p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Lift and Shift.</p>",
                    "<p>The migration team decided to use containers and the Kubernetes Engine. This migration strategy is called Remove and Replace.</p>"
                ]
            },
            "correct_response": [
                "a",
                "b"
            ],
            "section": "",
            "question_plain": "A company is moving an enterprise application to the Google Cloud. This application runs on a cluster of virtual machines on private data center, and workloads are distributed by a load balancer. Select all true statements. (select 2)",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163928,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your organization has a large monolithic application running on-premises that has become difficult to maintain and scale. The application has a relational database backend and a web-based frontend. You have been tasked with migrating this application to Google Cloud Platform (GCP) and breaking it down into microservices. Which of the following strategies should you use?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Refactor the application into microservices on-premises, then migrate each microservice to GCP one at a time. -&gt;&nbsp;Correct. Refactoring the application into microservices before migration allows you to manage and mitigate issues on a smaller scale and reduces risk during the migration. Each microservice can be tested and validated independently.</p><p><br></p><p>Lift-and-shift migration, moving the application to GCP as-is, and then refactoring it into microservices. -&gt;&nbsp;Incorrect. While this strategy will get your application onto GCP quickly, refactoring a monolithic application into microservices while it is running could be disruptive and increase the complexity of the migration.</p><p><br></p><p>Use Anthos Migrate to containerize the application and migrate it to GCP. -&gt;&nbsp;Incorrect. While Anthos Migrate can be used to containerize and migrate applications, it doesn't break down monolithic applications into microservices.</p><p><br></p><p>Use Cloud Endpoints to break down the monolithic application into microservices, then migrate to GCP. -&gt;&nbsp;Incorrect. Cloud Endpoints is a tool for developing, deploying, protecting, and monitoring APIs, not for breaking down monolithic applications into microservices.</p>",
                "answers": [
                    "<p>Refactor the application into microservices on-premises, then migrate each microservice to GCP one at a time.</p>",
                    "<p>Lift-and-shift migration, moving the application to GCP as-is, and then refactoring it into microservices.</p>",
                    "<p>Use Anthos Migrate to containerize the application and migrate it to GCP.</p>",
                    "<p>Use Cloud Endpoints to break down the monolithic application into microservices, then migrate to GCP.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your organization has a large monolithic application running on-premises that has become difficult to maintain and scale. The application has a relational database backend and a web-based frontend. You have been tasked with migrating this application to Google Cloud Platform (GCP) and breaking it down into microservices. Which of the following strategies should you use?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163930,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you set up the optimal combination of CPU and memory resources for nodes in a Kubernetes cluster. You want to be notified whenever CPU utilization exceeds 80% for 5 minutes or when memory utilization exceeds 90% for 1 minute. What do you need to specify to receive such notifications?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>An alerting policy -&gt; Correct. An alerting policy allows you to define conditions and thresholds for triggering notifications or alerts based on specific metrics or events. In this case, you would set up an alerting policy to monitor CPU utilization and memory utilization in the Kubernetes cluster and specify the conditions for triggering notifications when the thresholds are exceeded.</p><p><br></p><p>An alerting condition -&gt;&nbsp;Incorrect. While an alerting condition is related to the concept of alerts, it alone does not provide the mechanism to receive notifications. It is part of an alerting policy and defines the specific conditions that need to be met for an alert to be triggered.</p><p><br></p><p>Cloud Pub/Sub topic -&gt;&nbsp;Incorrect. Cloud Pub/Sub is a messaging service provided by Google Cloud Platform, and it is not directly related to receiving notifications for resource utilization in a Kubernetes cluster.</p><p><br></p><p>A logging message specification -&gt;&nbsp;Incorrect. A logging message specification is not directly related to receiving notifications for resource utilization. Logging messages are typically used for recording events and activities in a system, and they are not the appropriate mechanism for real-time notifications based on resource utilization thresholds.</p><p><br></p><p>https://cloud.google.com/monitoring/alerts</p>",
                "answers": [
                    "<p>An alerting policy</p>",
                    "<p>An alerting condition</p>",
                    "<p>Cloud Pub/Sub topic</p>",
                    "<p>A logging message specification</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you set up the optimal combination of CPU and memory resources for nodes in a Kubernetes cluster. You want to be notified whenever CPU utilization exceeds 80% for 5 minutes or when memory utilization exceeds 90% for 1 minute. What do you need to specify to receive such notifications?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163932,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your company's finance department has notified you that logs generated by a financial application will need to be kept for five years. It is not likely to be accessed, but it has to be available if needed within three days. How would you recommend storing that data?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should export it to Cloud Storage and use Coldline class storage. -&gt; Correct. Cloud Storage provides durable and scalable object storage for various use cases. The Coldline storage class in Cloud Storage is specifically designed for long-term data archival with infrequent access. By exporting the logs to Cloud Storage and using the Coldline storage class, you can ensure cost-effective storage for the logs that need to be kept for five years while still maintaining availability if needed within three days.</p><p><br></p><p>You should store it in Cloud Logging. -&gt; Incorrect. Cloud Logging is a service provided by Google Cloud for collecting, storing, and analyzing logs and can be used for real-time monitoring and analysis. However, it may not be the most cost-effective or scalable solution for long-term archival storage of logs.</p><p><br></p><p>You should export it to BigQuery. -&gt; Incorrect. BigQuery is a fully managed data warehouse and analytics platform, which provides powerful querying and analysis capabilities. While it can handle large volumes of data and support long-term storage, it may not be the most cost-effective solution if the logs are not expected to be frequently accessed or analyzed.</p><p><br></p><p>You should export it to Cloud Pub/Sub. -&gt; Incorrect. Cloud Pub/Sub is a messaging service that provides reliable, real-time messaging between applications. While it can be used for distributing messages and events, it is not designed for long-term storage and retrieval of logs.</p><p><br></p><p>https://cloud.google.com/storage/docs/storage-classes#coldline</p>",
                "answers": [
                    "<p>You should export it to Cloud Storage and use Coldline class storage.</p>",
                    "<p>You should store it in Cloud Logging.</p>",
                    "<p>You should export it to BigQuery.</p>",
                    "<p>You should export it to Cloud Pub/Sub.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your company's finance department has notified you that logs generated by a financial application will need to be kept for five years. It is not likely to be accessed, but it has to be available if needed within three days. How would you recommend storing that data?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163934,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A shipment tracking application receives data from sensors. Sometimes more data arrives than the virtual machines can process. As a cloud architect, you don't want to use additional virtual machines and you also need the most economical solution. What can you do to prevent data loss?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should write data to the Cloud Pub/Sub queue, and the application should read data from the queue. -&gt; Correct. It provides a scalable and economical solution for handling spikes in data volume. Cloud Pub/Sub is a fully-managed messaging service that allows applications to send and receive messages between independent systems. It can handle a high volume of messages and can scale automatically to handle spikes in traffic. By writing data to a Cloud Pub/Sub queue, the application can read the data as it is able to process it. This ensures that data is not lost and that the application can keep up with incoming data even during spikes in volume.</p><p><br></p><p>You should write data to local SSDs on the Compute Engine virtual machines. -&gt; Incorrect.&nbsp; It is not a scalable solution because it does not provide a way to distribute the data across multiple machines. In addition, local SSDs are not persistent, so data can be lost if the virtual machine fails or is restarted.</p><p><br></p><p>You should write data to Cloud Memorystore, and the application should read data from the cache. -&gt; Incorrect. It is not a good solution for this scenario because it is a caching service, not a messaging service. Caching services are designed to store frequently-accessed data to improve application performance. They are not intended to handle spikes in data volume and are not a reliable mechanism for storing large volumes of data.</p><p><br></p><p>You should increase the CPU. -&gt; Incorrect. It is not a good solution for this scenario because it does not address the underlying problem of handling spikes in data volume. Increasing the CPU may help the application process data faster, but it does not provide a mechanism for handling large volumes of incoming data.</p><p><br></p><p>https://cloud.google.com/pubsub/docs/create-topic-console</p>",
                "answers": [
                    "<p>You should write data to the Cloud Pub/Sub queue, and the application should read data from the queue.</p>",
                    "<p>You should write data to local SSDs on the Compute Engine virtual machines.</p>",
                    "<p>You should write data to Cloud Memorystore, and the application should read data from the cache.</p>",
                    "<p>You should increase the CPU.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A shipment tracking application receives data from sensors. Sometimes more data arrives than the virtual machines can process. As a cloud architect, you don't want to use additional virtual machines and you also need the most economical solution. What can you do to prevent data loss?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163936,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect responsible for preparing a migration strategy, you are confronted with a scenario where a company possesses sensitive data that must be encrypted using keys under their control. The objective is to store the data in GCP while minimizing costs and operational overhead. What recommendations would you propose in this scenario?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should use Cloud KMS for sensitive data. -&gt; Correct. Cloud Key Management Service (KMS) is a fully managed service that allows you to encrypt data at rest with your own encryption keys. By using Cloud KMS, you can encrypt sensitive data stored in GCP and manage your own encryption keys without the operational overhead of managing your own key management system.</p><p><br></p><p>You should use Google default encryption for the data. -&gt; Incorrect. Google default encryption, on the other hand, is a feature that encrypts data by default using a unique encryption key created by Google, and is useful for preventing unauthorized access to data in the event of a data breach. However, if you need to control the encryption keys and have the ability to rotate, revoke or manage access to them, then you should use Cloud KMS.</p><p><br></p><p>You should use a custom encryption algorithm for the data. -&gt; Incorrect. Using a custom encryption algorithm is not recommended, as it can be difficult to manage and may not be as secure as using a standard, tested encryption algorithm.</p><p><br></p><p>You cannot use your own keys with GCP. -&gt; Incorrect. It is important to note that GCP does allow you to bring your own encryption keys for many of its services, including Cloud Storage, Cloud SQL, and Cloud Bigtable, but not for all services.</p><p><br></p><p>https://cloud.google.com/kms/docs/create-encryption-keys</p>",
                "answers": [
                    "<p>You should use Cloud KMS for sensitive data.</p>",
                    "<p>You should use Google default encryption for the data.</p>",
                    "<p>You should use a custom encryption algorithm for the data.</p>",
                    "<p>You cannot use your own keys with GCP.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect responsible for preparing a migration strategy, you are confronted with a scenario where a company possesses sensitive data that must be encrypted using keys under their control. The objective is to store the data in GCP while minimizing costs and operational overhead. What recommendations would you propose in this scenario?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163938,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your organization has multiple applications deployed across different environments (development, staging, production) in Google Cloud. Recently, a misconfiguration in a configuration file led to a major issue in the production environment. To avoid such incidents in the future, what should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Google Cloud Build to automate builds and apply automatic testing of configuration files. -&gt;&nbsp;Correct. Cloud Build allows for the creation of a continuous integration/continuous deployment (CI/CD) pipeline, which can include automatic testing of configuration files. This approach can identify and prevent errors before deployment to the production environment.</p><p><br></p><p>Enforce manual reviews for all configuration files before deployment. -&gt;&nbsp;Incorrect. While manual reviews can help, they are not foolproof, and errors can still be overlooked. This approach is also time-consuming and doesn't scale well.</p><p><br></p><p>Utilize Google Cloud Deployment Manager to automate deployment of resources and configuration files. -&gt;&nbsp;Incorrect. While Deployment Manager can automate the deployment process, it doesn't inherently prevent or mitigate the risk of configuration errors.</p><p><br></p><p>Utilize Google Cloud Shell to execute configuration changes. -&gt;&nbsp;Incorrect. Cloud Shell is more of an interactive shell environment and doesn't inherently provide mechanisms to prevent or catch configuration errors.</p>",
                "answers": [
                    "<p>Use Google Cloud Build to automate builds and apply unit tests to configuration files.</p>",
                    "<p>Enforce manual reviews for all configuration files before deployment.</p>",
                    "<p>Utilize Google Cloud Deployment Manager to automate deployment of resources and configuration files.</p>",
                    "<p>Utilize Google Cloud Shell to execute configuration changes.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your organization has multiple applications deployed across different environments (development, staging, production) in Google Cloud. Recently, a misconfiguration in a configuration file led to a major issue in the production environment. To avoid such incidents in the future, what should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163940,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your company has a hybrid cloud computing model and your current network connection is using 50% of&nbsp;bandwidth. As a cloud architect, you are concerned that you only have one connection that you might lose in the event of a failure. What would you do to minimize this risk?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should use redundant network connections between the on-premises data center and GCP. -&gt; Correct. Using redundant network connections between the on-premises data center and Google Cloud Platform helps to minimize the risk of network failure. This can be achieved by configuring multiple connections and using load balancing to distribute the traffic across them. If one connection fails, the traffic is automatically rerouted to the other connection, ensuring that the network remains available.</p><p><br></p><p>You should increase the bandwidth of your current network connection.&nbsp; -&gt; Incorrect. It may help to improve network performance, but it does not address the risk of network failure.</p><p><br></p><p>You should increase the number of virtual machines for your workload. -&gt; Incorrect. It may improve workload performance, but it does not address the risk of network failure.</p><p><br></p><p>You should increase the performance of virtual machine disks. -&gt; Incorrect. It may help to improve disk performance, but it does not address the risk of network failure.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/interconnect/how-to/dedicated/creating-redundant-interconnect</p>",
                "answers": [
                    "<p>You should use redundant network connections between the on-premises data center and GCP.</p>",
                    "<p>You should increase the bandwidth of your current network connection. </p>",
                    "<p>You should increase the number of virtual machines for your workload.</p>",
                    "<p>You should increase the performance of virtual machine disks.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your company has a hybrid cloud computing model and your current network connection is using 50% of&nbsp;bandwidth. As a cloud architect, you are concerned that you only have one connection that you might lose in the event of a failure. What would you do to minimize this risk?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163942,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A Managed Instance Group adds more virtual machines than necessary, and then shuts them down. This pattern is repeated many times. What would you do to stabilize adding and removing virtual machines?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should increase the time autoscalers consider when making decisions. -&gt;&nbsp;Correct. It is correct because the autoscaler is adding and removing virtual machines too quickly, causing instability in the Managed Instance Group. By increasing the time the autoscaler considers when making decisions, it will allow for more stable and gradual changes in the number of virtual machines added and removed from the group.</p><p><br></p><p>You should decrease the time autoscalers consider when making decisions. -&gt; Incorrect. Decreasing the time autoscalers consider when making decisions, would further exacerbate the issue by causing even quicker changes in the number of virtual machines added and removed from the group.</p><p><br></p><p>You should increase the maximum number of virtual machines in a Managed Instance Group. -&gt; Incorrect. Increasing the maximum number of virtual machines in a Managed Instance Group, is not relevant to the issue at hand. The problem is not with the maximum number of virtual machines but with the instability caused by the rapid adding and removing of virtual machines.</p><p><br></p><p>You should decrease the maximum number of virtual machines in a Managed Instance Group. -&gt; Incorrect. Decreasing the maximum number of virtual machines in a Managed Instance Group, would limit the capacity of the group and not address the issue of instability caused by rapid changes in the number of virtual machines.</p><p><br></p><p>https://cloud.google.com/compute/docs/autoscaler</p>",
                "answers": [
                    "<p>You should increase the time autoscalers consider when making decisions.</p>",
                    "<p>You should decrease the time autoscalers consider when making decisions.</p>",
                    "<p>You should increase the maximum number of virtual machines in a Managed Instance Group.</p>",
                    "<p>You should decrease the maximum number of virtual machines in a Managed Instance Group.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "A Managed Instance Group adds more virtual machines than necessary, and then shuts them down. This pattern is repeated many times. What would you do to stabilize adding and removing virtual machines?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163944,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you are responsible for implementing a new application using a microservices architecture. You would like to run each microservice in containers. In addition, you want to minimize DevOps overhead and benefit from autoscaling. What should you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should run the containers in Kubernetes Engine. -&gt; Correct. Kubernetes Engine is a managed Kubernetes service provided by Google Cloud. It allows you to deploy and manage containers at scale, providing features like container orchestration, automatic scaling, load balancing, and automated rollout and rollback capabilities. Running microservices in containers on Kubernetes Engine enables you to minimize DevOps overhead and benefit from autoscaling, making it an ideal choice for a microservices architecture.</p><p><br></p><p>You should run the containers in Managed Instance Group. -&gt;&nbsp;Incorrect. Managed Instance Groups are primarily used for managing groups of virtual machine instances, providing features like autoscaling and load balancing at the virtual machine level. While you can run containers within virtual machines, it does not provide the native container orchestration and management capabilities of Kubernetes Engine.</p><p><br></p><p>You should run the containers in Unmanaged Instance Group. -&gt;&nbsp;Incorrect. Unmanaged Instance Groups are similar to Managed Instance Groups, but they require more manual configuration and management of virtual machine instances. They do not provide the native container orchestration and management capabilities required for running containers at scale.</p><p><br></p><p>You should use App Engine for this. -&gt;&nbsp;Incorrect. App Engine is a platform-as-a-service (PaaS) offering that provides a runtime environment for running applications without needing to manage the underlying infrastructure. While App Engine supports running applications in containers using the flexible environment, it may not provide the same level of control and flexibility required for a microservices architecture.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs/quickstart</p>",
                "answers": [
                    "<p>You should run the containers in Kubernetes Engine.</p>",
                    "<p>You should run the containers in Managed Instance Group.</p>",
                    "<p>You should run the containers in Unmanaged Instance Group.</p>",
                    "<p>You should use App Engine for this.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you are responsible for implementing a new application using a microservices architecture. You would like to run each microservice in containers. In addition, you want to minimize DevOps overhead and benefit from autoscaling. What should you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163946,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>For your application to function properly, it necessitates a filesystem that can be mounted using operating system commands. Furthermore, this filesystem must be accessible from numerous virtual machine instances. Which Google Cloud Platform (GCP) service would you suggest?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Cloud Filestore -&gt; Correct. Cloud Filestore is a managed file storage service that makes it easy for applications to access fully managed NFS file shares. The service can be used to create a filesystem that can be mounted using operating system commands and can be shared between multiple virtual machine instances. </p><p><br></p><p>Cloud SQL -&gt;&nbsp;Incorrect. Cloud SQL is a fully-managed relational database that supports SQL. It does not provide a file system that can be mounted using operating system commands, so it wouldn't be suitable for this use-case.</p><p><br></p><p>Cloud Spanner -&gt;&nbsp;Incorrect. This is a globally distributed, horizontally scalable database service. It's not a file system, and therefore doesn't fit the requirement of being mounted using OS commands.</p><p><br></p><p>Cloud Firestore -&gt; Incorrect. This is a NoSQL document database and, like Cloud Spanner and Cloud SQL, doesn't provide the file system capabilities required.</p><p><br></p><p>https://cloud.google.com/filestore/docs/create-instance-console</p>",
                "answers": [
                    "<p>Cloud Filestore</p>",
                    "<p>Cloud SQL</p>",
                    "<p>Cloud Spanner</p>",
                    "<p>Cloud Firestore</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "For your application to function properly, it necessitates a filesystem that can be mounted using operating system commands. Furthermore, this filesystem must be accessible from numerous virtual machine instances. Which Google Cloud Platform (GCP) service would you suggest?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163948,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you have the following three options for deploying MySQL database:</p><p>1. Use Cloud SQL.</p><p>2. Use Cloud Marketplace with click-to-deploy interface to install MySQL onto a Compute Engine instance.</p><p>3. Manually install and customize MySQL on your Compute Engine instance.</p><p><br></p><p>You want to minimize administrative duties as much as possible. Which option should you use?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>1 -&gt; Correct. Using Cloud SQL minimizes administrative duties as it is a fully managed service, which means Google Cloud takes care of many of the administrative tasks, such as patching, backups, and updates. Other options require more administrative duties as they involve managing and maintaining the infrastructure of the Compute Engine instance that hosts MySQL.</p><p><br></p><p>https://cloud.google.com/architecture/setup-mysql?hl=en#how_to_choose_the_right_mysql_deployment_option</p>",
                "answers": [
                    "<p>1</p>",
                    "<p>2</p>",
                    "<p>3</p>",
                    "<p>All options have the same administrative duties.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you have the following three options for deploying MySQL database:1. Use Cloud SQL.2. Use Cloud Marketplace with click-to-deploy interface to install MySQL onto a Compute Engine instance.3. Manually install and customize MySQL on your Compute Engine instance.You want to minimize administrative duties as much as possible. Which option should you use?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163950,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Anonymous users from all over the world access a public information website hosted in an on-premises data center. The servers that host this website are older, and users are complaining about slow response times. There has also been an increase in distributed denial-of-service attacks targeting a website in recent times. Attacks always come from the same IP address ranges. The management has identified the public information website as an easy, low risk application to migrate to Google Cloud. You need to improve access latency and provide a security solution that will prevent the denial-of-service traffic from entering your Virtual Private Cloud (VPC) network. What should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should deploy an external HTTP(S) load balancer, configure Google Cloud Armor, and move the application onto Compute Engine virtual machines. -&gt;&nbsp;Correct. The external HTTP(s) load balancer will improve access latency and Cloud Armor can be configured to block the Distributed Denial-of-Service (DDoS) attack.</p><p><br></p><p>You should deploy an external HTTP(S) load balancer, configure VPC firewall rules, and move the applications onto Compute Engine virtual machines. -&gt; Incorrect. Firewall rules do not block malicious traffic into a VPC but rather block it at the VM level.</p><p><br></p><p>You should containerize the application and move it into Google Kubernetes Engine (GKE). Create a GKE service to expose the pods within the cluster, and set up a GKE network policy. -&gt; Incorrect. GKE service does not expose a set of pods outside of a cluster and a GKE network policy only filters traffic between pods and services.</p><p><br></p><p>You should containerize the application and move it into Google Kubernetes Engine (GKE). Create an internal load balancer to expose the pods outside the cluster, and configure Identity-Aware Proxy (IAP) for access.-&gt;Incorrect. GKE internal load balancer will not load balance external traffic and anonymous users need access to the website so IAP is not a fit.</p>",
                "answers": [
                    "<p>You should deploy an external HTTP(S) load balancer, configure Google Cloud Armor, and move the application onto Compute Engine virtual machines.</p>",
                    "<p>You should deploy an external HTTP(S) load balancer, configure VPC firewall rules, and move the applications onto Compute Engine virtual machines.</p>",
                    "<p>You should containerize the application and move it into Google Kubernetes Engine (GKE). Create a GKE service to expose the pods within the cluster, and set up a GKE network policy.</p>",
                    "<p>You should containerize the application and move it into Google Kubernetes Engine (GKE). Create an internal load balancer to expose the pods outside the cluster, and configure Identity-Aware Proxy (IAP) for access.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Anonymous users from all over the world access a public information website hosted in an on-premises data center. The servers that host this website are older, and users are complaining about slow response times. There has also been an increase in distributed denial-of-service attacks targeting a website in recent times. Attacks always come from the same IP address ranges. The management has identified the public information website as an easy, low risk application to migrate to Google Cloud. You need to improve access latency and provide a security solution that will prevent the denial-of-service traffic from entering your Virtual Private Cloud (VPC) network. What should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163952,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Refer to the EHR Healthcare case study for this question: https://services.google.com/fh/files/blogs/master_case_study_ehr_healthcare.pdf</p><p><br></p><p>EHR is interested in establishing a connection between one of its data centers and Google Cloud. However, the data center is situated in a remote location that is over 100 kilometers away from a Google-owned point of presence (POP). Budget constraints prevent them from acquiring new hardware, but&nbsp; an existing firewall can accommodate future throughput growth. Additionally, they provided the following information:</p><ul><li><p>communication is required between servers in their on-premises data center and Google Kubernetes Engine (GKE) resources in the cloud</p></li><li><p>both on-premises servers and cloud resource are set up with private RFC 1918 IP addresses</p></li><li><p>the service provider has notified the customer that basic internet connectivity is provided as a best-effort service and does not come with any service level agreement (SLA)</p></li></ul><p><br></p><p>In your role as a cloud architect, what connectivity option would you recommend?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Provision a Partner Interconnect connection. -&gt;&nbsp;Correct. It allows the customer to lower latency by connecting directly to a partner network that is directly connected to Google.</p><p><br></p><p>Provision Carrier Peering. -&gt;&nbsp;Incorrect. It does not give private IP addressing across the connection.</p><p><br></p><p>Provision a new Internet connection. -&gt; Incorrect. An additional Internet connection will not provide RFC1918 communications by itself.</p><p><br></p><p>Provision a Dedicated Interconnect connection. -&gt; Incorrect. Dedicated Interconnect would require the customer to buy new hardware to get a 10 gig interface for their firewall.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/interconnect/concepts/partner-overview</p>",
                "answers": [
                    "<p>Provision a Partner Interconnect connection.</p>",
                    "<p>Provision a new Internet connection.</p>",
                    "<p>Provision Carrier Peering.</p>",
                    "<p>Provision a Dedicated Interconnect connection.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Refer to the EHR Healthcare case study for this question: https://services.google.com/fh/files/blogs/master_case_study_ehr_healthcare.pdfEHR is interested in establishing a connection between one of its data centers and Google Cloud. However, the data center is situated in a remote location that is over 100 kilometers away from a Google-owned point of presence (POP). Budget constraints prevent them from acquiring new hardware, but&nbsp; an existing firewall can accommodate future throughput growth. Additionally, they provided the following information:communication is required between servers in their on-premises data center and Google Kubernetes Engine (GKE) resources in the cloudboth on-premises servers and cloud resource are set up with private RFC 1918 IP addressesthe service provider has notified the customer that basic internet connectivity is provided as a best-effort service and does not come with any service level agreement (SLA)In your role as a cloud architect, what connectivity option would you recommend?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163954,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>In your role as a cloud architect, you are in the process of designing a hybrid environment that is future-proof and necessitates a network connection between Google Cloud and your on-premises infrastructure. Your objective is to guarantee compatibility between the Google Cloud environment you are designing and your existing on-premises network environment. What course of action should you take?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should create a network plan for your VPC in Google Cloud that uses non-overlapping CIDR ranges with your on-premises environment. Use a Cloud Interconnect connection between your on-premises environment and Google Cloud. -&gt;&nbsp;Correct. This ensures your on premises network is compatible with your Google Cloud VPC.</p><p><br></p><p>You should use the default VPC in your Google Cloud project. Use a Cloud VPN connection between your on-premises environment and Google Cloud. -&gt; Incorrect. The default VPC is a VPC with Auto Mode IP ranges.</p><p><br></p><p>You should create a custom VPC in Google Cloud in auto mode. Use a Cloud VPN connection between your on-premises environment and Google Cloud. -&gt; Incorrect. With Auto Mode IP Ranges there is no guarantee that the IP ranges will not overlap with your on premises environment, either now or in the future.</p><p><br></p><p>You should create a network plan for your VPC in Google Cloud that uses CIDR ranges that overlap with your on-premises environment. Use a Cloud Interconnect connection between your on-premises environment and Google Cloud. -&gt;&nbsp;Incorrect. To ensure correct routing, ranges cannot overlap between environments.</p><p><br></p><p>https://cloud.google.com/vpc/docs/vpc#ip-ranges</p>",
                "answers": [
                    "<p>You should create a network plan for your VPC in Google Cloud that uses non-overlapping CIDR ranges with your on-premises environment. Use a Cloud Interconnect connection between your on-premises environment and Google Cloud.</p>",
                    "<p>You should use the default VPC in your Google Cloud project. Use a Cloud VPN connection between your on-premises environment and Google Cloud.</p>",
                    "<p>You should create a custom VPC in Google Cloud in auto mode. Use a Cloud VPN connection between your on-premises environment and Google Cloud.</p>",
                    "<p>You should create a network plan for your VPC in Google Cloud that uses CIDR ranges that overlap with your on-premises environment. Use a Cloud Interconnect connection between your on-premises environment and Google Cloud.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "In your role as a cloud architect, you are in the process of designing a hybrid environment that is future-proof and necessitates a network connection between Google Cloud and your on-premises infrastructure. Your objective is to guarantee compatibility between the Google Cloud environment you are designing and your existing on-premises network environment. What course of action should you take?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163956,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>In your role as a cloud architect, you are tasked with designing a large distributed application comprising 20 microservices. Each of these microservices must connect to the database backend. Your objective is to ensure the secure storage of credentials for these connections. What is the recommended storage location for the credentials?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>In a secret management system -&gt;&nbsp;Correct. A secret management system such as Secret Manager is a secure and convenient storage system for API keys, passwords, certificates, and other sensitive data. Secret Manager provides a central place and single source of truth to manage, access, and audit secrets across Google Cloud.</p><p><br></p><p>In the source code -&gt;&nbsp;Incorrect. Storing credentials in source code and source control is discoverable, in plain text, by anyone with access to the source code. This also introduces the requirement to update code and do a deployment each time the credentials are rotated.</p><p><br></p><p>In an environment variable -&gt; Incorrect. Consistently populating environment variables would require the credentials to be available, in plain text, when the session is started.</p><p><br></p><p>In a config file that has restricted access through ACLs -&gt; Incorrect. Instead of managing access to the config file and updating manually as keys are rotated, it would be better to leverage a key management system. Additionally, there is increased risk if the config file contains the credentials in plain text.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs/tutorials/workload-identity-secrets</p>",
                "answers": [
                    "<p>In a secret management system</p>",
                    "<p>In the source code</p>",
                    "<p>In an environment variable</p>",
                    "<p>In a config file that has restricted access through ACLs</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "In your role as a cloud architect, you are tasked with designing a large distributed application comprising 20 microservices. Each of these microservices must connect to the database backend. Your objective is to ensure the secure storage of credentials for these connections. What is the recommended storage location for the credentials?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163958,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Refer to the TerramEarth case study for this question: https://services.google.com/fh/files/blogs/master_case_study_terramearth.pdf</p><p><br></p><p>To account for potential future use cases of the data collected by TerramEarth, a decision has been made to construct a system that captures and stores all raw data, ensuring its availability for future needs. As a cloud architect, what would be the most cost-effective approach to achieve this objective?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should have the vehicles in the field continue to dump data via FTP, and adjust the existing Linux machines to immediately upload it to Cloud Storage with <code>gsutil</code>. -&gt;&nbsp;Several load-balanced Compute Engine VMs would suffice to ingest 9 TB per day, and Cloud Storage is the cheapest per-byte storage offered by Google. Depending on the format, the data could be available via BigQuery immediately, or shortly after running through an ETL job. Thus, this solution meets business and technical requirements while optimizing for cost.</p><p><br></p><p>You should have the vehicles in the field stream the data directly into BigQuery. -&gt; Incorrect. TerramEarth has cellular service for 200,000 vehicles, and each vehicle sends at least one row (120 fields) per second. This exceeds BigQuery's maximum rows per second per project quota[1]. Additionally, there are 20 million total vehicles, most of which perform uploads when connected by a maintenance port, which drastically exceeds the streaming project quota further.</p><p><br></p><p>You should have the vehicles in the field pass the data to Cloud Pub/Sub and dump it into a Cloud Dataproc cluster that stores data in Apache Hadoop Distributed File System (HDFS) on persistent disks. -&gt; Incorrect. Although Cloud Pub/Sub is a fine choice for this application, Cloud Dataproc is probably not. The question posed asks us to optimize for cost. Because Cloud Dataproc is optimized for ephemeral, job-scoped clusters, a long-running cluster with large amounts of HDFS storage could be very expensive to build and maintain when compared to managed and specialized storage solutions like Cloud Storage.</p><p><br></p><p>You should have the vehicles in the field continue to dump data via FTP, adjust the existing Linux machines, and use a collector to upload them into Cloud Dataproc HDFS for storage -&gt;&nbsp;Incorrect. The question asks us to optimize for cost, and because Cloud Dataproc is optimized for ephemeral, job-scoped clusters, a long-running cluster with large amounts of HDFS storage could be very expensive to build and maintain when compared to managed and specialized storage solutions like Cloud Storage.</p>",
                "answers": [
                    "<p>You should have the vehicles in the field continue to dump data via FTP, and adjust the existing Linux machines to immediately upload it to Cloud Storage with <code>gsutil</code>.</p>",
                    "<p>You should have the vehicles in the field stream the data directly into BigQuery.</p>",
                    "<p>You should have the vehicles in the field pass the data to Cloud Pub/Sub and dump it into a Cloud Dataproc cluster that stores data in Apache Hadoop Distributed File System (HDFS) on persistent disks.</p>",
                    "<p>You should have the vehicles in the field continue to dump data via FTP, adjust the existing Linux machines, and use a collector to upload them into Cloud Dataproc HDFS for storage</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Refer to the TerramEarth case study for this question: https://services.google.com/fh/files/blogs/master_case_study_terramearth.pdfTo account for potential future use cases of the data collected by TerramEarth, a decision has been made to construct a system that captures and stores all raw data, ensuring its availability for future needs. As a cloud architect, what would be the most cost-effective approach to achieve this objective?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163960,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>To implement a disaster recovery plan, your company is currently working on replicating its production MySQL database from a private data center to a GCP project utilizing a Google Cloud VPN connection. However, there are latency issues and a minor packet loss occurring during the replication process, causing disruptions. What course of action should they take?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Configure a Google Cloud Dedicated Interconnect. -&gt; Correct. Google Cloud Dedicated Interconnect is a dedicated, high-speed, low-latency connectivity option that enables data replication between on-premises data centers and GCP projects. It provides a direct physical connection between your on-premises network and Google's network, which can reduce latency and packet loss. In this case, using Google Cloud Dedicated Interconnect would likely resolve the latency issues and packet loss that the company is experiencing with their VPN connection.</p><p><br></p><p>Configure their replication to use UDP. -&gt; Incorrect. It may help reduce latency, but it would not necessarily address the packet loss issue.</p><p><br></p><p>Restore their database daily using Google Cloud SQL. -&gt; Incorrect. It is not a real-time replication solution and would not provide the same level of protection as real-time replication.</p><p><br></p><p>Add additional VPN connections and load balance them. -&gt; Incorrect. It would not necessarily address the underlying latency and packet loss issues and could add additional complexity and cost.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/interconnect/concepts/dedicated-overview</p>",
                "answers": [
                    "<p>Configure a Google Cloud Dedicated Interconnect.</p>",
                    "<p>Configure their replication to use UDP.</p>",
                    "<p>Restore their database daily using Google Cloud SQL.</p>",
                    "<p>Add additional VPN connections and load balance them.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "To implement a disaster recovery plan, your company is currently working on replicating its production MySQL database from a private data center to a GCP project utilizing a Google Cloud VPN connection. However, there are latency issues and a minor packet loss occurring during the replication process, causing disruptions. What course of action should they take?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163962,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>In your Compute Engine managed instance group, an outage has occurred where all instances are continuously restarting every 6 seconds. Although you have a configured health check, autoscaling is currently disabled. To address this issue, your Linux expert colleague has offered to investigate. Your task is to ensure that your colleague has appropriate access to the VMs for troubleshooting purposes. What should you do?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Disable the health check for the instance group. Add his SSH key to the project-wide SSH Keys. -&gt; Correct. By disabling the health check, the instances will stop restarting every 6 seconds. This allows your colleague to access the VMs without being interrupted by the restart process. Adding the colleague's SSH key to the project-wide SSH keys grants them access to the VMs for troubleshooting purposes.</p><p><br></p><p>Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH keys. -&gt; Incorrect. Disabling autoscaling does not directly address the issue of continuous restarts every 6 seconds. It is the health check that triggers the restarts, so disabling the health check is the more appropriate action. Adding the SSH key to the project-wide SSH keys is still valid for granting access to the colleague.</p><p><br></p><p>Perform a rolling restart on the instance group. -&gt; Incorrect. Performing a rolling restart on the instance group might not address the underlying cause of the continuous restarts. It could disrupt the VMs further and might not be necessary if the issue is related to the health check.</p><p><br></p><p>Grant your colleague the IAM role of project Viewer. -&gt; Incorrect. Granting the project Viewer role would provide read-only access to the project but may not necessarily address the issue at hand. It is more important to disable the health check and provide appropriate access for troubleshooting purposes.</p><p><br></p><p>https://cloud.google.com/compute/docs/connect/add-ssh-keys</p>",
                "answers": [
                    "<p>Disable the health check for the instance group. Add his SSH key to the project-wide SSH keys.</p>",
                    "<p>Disable autoscaling for the instance group. Add his SSH key to the project-wide SSH keys.</p>",
                    "<p>Perform a rolling restart on the instance group.</p>",
                    "<p>Grant your colleague the IAM role of project Viewer.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "In your Compute Engine managed instance group, an outage has occurred where all instances are continuously restarting every 6 seconds. Although you have a configured health check, autoscaling is currently disabled. To address this issue, your Linux expert colleague has offered to investigate. Your task is to ensure that your colleague has appropriate access to the VMs for troubleshooting purposes. What should you do?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163964,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, you are tasked with designing an architecture for an application that will operate on Compute Engine. It is essential to create a disaster recovery plan that ensures the application can seamlessly switch to another region in the event of a regional outage. What course of action should you take?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should deploy the application on two Compute Engine instance groups, each in the same project but in a different region. Use the first instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster. -&gt; Correct. It provides the best solution for regional disaster recovery with minimal downtime. By deploying the application on two Compute Engine instance groups in different regions, traffic can be routed to the healthy instance group if one region becomes unavailable. HTTP load balancing can automatically detect a regional outage and redirect traffic to the healthy instance group in another region.</p><p><br></p><p>You should deploy the application on two Compute Engine instances in the same project but in a different region. Use the first instance to serve traffic, and use the HTTP load balancing service to fail over to the standby instance in case of a disaster. -&gt;&nbsp;Incorrect. Deploying the application on two Compute Engine instances in the same project but in a different region, does not provide the same level of redundancy as deploying it on instance groups. Instance groups provide the ability to automatically manage and scale a set of VM instances as a single entity. Additionally, instance groups can automatically restart failed instances, which can help minimize downtime in case of a failure.</p><p><br></p><p>You should deploy the application on a Compute Engine instance. Use the instance to serve traffic, and use the HTTP load balancing service to fail over to an instance on your premises in case of a disaster. -&gt; Incorrect. Deploying the application on a Compute Engine instance and using the HTTP load balancing service to fail over to an instance on your premises in case of a disaster, introduces more complexity into the architecture, as it requires a network connection between your on-premises infrastructure and the Google Cloud Platform (GCP) infrastructure. It also introduces additional network latency that may affect the performance of the application.</p><p><br></p><p>You should deploy the application on two Compute Engine instance groups, each in a separate project and a different region. Use the first instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster. -&gt; Incorrect. Deploying the application on two Compute Engine instance groups in separate projects, adds additional complexity to the architecture and requires cross-project network connectivity. This can increase the risk of misconfiguration or failure in the network, which could lead to additional downtime in case of a disaster.</p><p><br></p><p>https://cloud.google.com/architecture/disaster-recovery</p>",
                "answers": [
                    "<p>You should deploy the application on two Compute Engine instance groups, each in the same project but in a different region. Use the first instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster.</p>",
                    "<p>You should deploy the application on two Compute Engine instances in the same project but in a different region. Use the first instance to serve traffic, and use the HTTP load balancing service to fail over to the standby instance in case of a disaster.</p>",
                    "<p>You should deploy the application on a Compute Engine instance. Use the instance to serve traffic, and use the HTTP load balancing service to fail over to an instance on your premises in case of a disaster.</p>",
                    "<p>You should deploy the application on two Compute Engine instance groups, each in a separate project and a different region. Use the first instance group to serve traffic, and use the HTTP load balancing service to fail over to the standby instance group in case of a disaster.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, you are tasked with designing an architecture for an application that will operate on Compute Engine. It is essential to create a disaster recovery plan that ensures the application can seamlessly switch to another region in the event of a regional outage. What course of action should you take?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163966,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>As a cloud architect, your role involves developing an application using various microservices that should remain internal to the cluster. Your objective is to configure each microservice with a designated number of replicas. Additionally, you aim to establish a uniform addressing mechanism where any microservice can access a specific microservice, irrespective of its scaling level. This solution needs to be implemented on Google Kubernetes Engine. What course of action should you take in this situation?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster. -&gt; Correct. In a Kubernetes cluster, a Deployment is used to manage a set of identical Pods. Each Pod represents a single instance of a microservice. By deploying each microservice as a Deployment, the cloud architect can ensure that each microservice is replicated to the desired number of instances. To access the microservices, the cloud architect can expose each Deployment within the cluster using a Service. A Service provides a stable DNS name that can be used to address the microservice, regardless of the number of replicas. This allows other microservices within the cluster to access a specific microservice in a uniform way.</p><p><br></p><p>Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster. -&gt; Incorrect. It is incorrect because an Ingress is used to expose HTTP and HTTPS routes from outside the cluster to services within the cluster. It is not appropriate for addressing microservices within the cluster.</p><p><br></p><p>Deploy each microservice as a Pod. Expose the Pod in the cluster using a Service, and use the Service DNS name to address the microservice from other microservices within the cluster. -&gt; Incorrect. It is incorrect because deploying each microservice as a Pod does not provide a way to ensure that the microservice is replicated to the desired number of instances. Using a Service to expose the Pod would provide a stable DNS name but would not ensure that the microservice is replicated.</p><p><br></p><p>Deploy each microservice as a Pod. Expose the Pod in the cluster using an Ingress, and use the Ingress IP address name to address the Pod from other microservices within the cluster. -&gt; Incorrect. It is incorrect because an Ingress is not appropriate for addressing microservices within the cluster.</p><p><br></p><p>https://cloud.google.com/kubernetes-engine/docs/how-to/deploying-workloads-overview</p>",
                "answers": [
                    "<p>Deploy each microservice as a Deployment. Expose the Deployment in the cluster using a Service, and use the Service DNS name to address it from other microservices within the cluster.</p>",
                    "<p>Deploy each microservice as a Deployment. Expose the Deployment in the cluster using an Ingress, and use the Ingress IP address to address the Deployment from other microservices within the cluster.</p>",
                    "<p>Deploy each microservice as a Pod. Expose the Pod in the cluster using a Service, and use the Service DNS name to address the microservice from other microservices within the cluster.</p>",
                    "<p>Deploy each microservice as a Pod. Expose the Pod in the cluster using an Ingress, and use the Ingress IP address name to address the Pod from other microservices within the cluster.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "As a cloud architect, your role involves developing an application using various microservices that should remain internal to the cluster. Your objective is to configure each microservice with a designated number of replicas. Additionally, you aim to establish a uniform addressing mechanism where any microservice can access a specific microservice, irrespective of its scaling level. This solution needs to be implemented on Google Kubernetes Engine. What course of action should you take in this situation?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163968,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Following your company's acquisition of another company, you have been assigned the task of integrating their existing Google Cloud environment with your company's data center. Upon examination, you uncover that certain RFC 1918 IP address ranges employed in the new company's Virtual Private Cloud (VPC) conflict with the IP address space utilized in your data center. What steps should you take to establish connectivity and prevent any routing conflicts once the connectivity is established?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply new IP addresses so there is no overlapping IP space. -&gt;&nbsp;Correct. This approach ensures that both VPC networks can communicate with each other without any routing conflicts as the IP addresses are unique to each VPC network.</p><p><br></p><p>Create a Cloud VPN connection from the new VPC to the data center, and create a Cloud NAT instance to perform NAT on the overlapping IP space. -&gt; Incorrect. This solution is not recommended as it does not eliminate the routing conflict, but rather creates a workaround by performing network address translation.</p><p><br></p><p>Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply a custom route advertisement to block the overlapping IP space. -&gt; Incorrect. This option does not address the problem of routing conflicts and may prevent communication between the two VPC networks.</p><p><br></p><p>Create a Cloud VPN connection from the new VPC to the data center, and apply a firewall rule that blocks the overlapping IP space. -&gt; Incorrect. This approach also does not address the routing conflict problem and may prevent communication between the two VPC networks.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/router</p>",
                "answers": [
                    "<p>Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply new IP addresses so there is no overlapping IP space.</p>",
                    "<p>Create a Cloud VPN connection from the new VPC to the data center, and create a Cloud NAT instance to perform NAT on the overlapping IP space.</p>",
                    "<p>Create a Cloud VPN connection from the new VPC to the data center, create a Cloud Router, and apply a custom route advertisement to block the overlapping IP space.</p>",
                    "<p>Create a Cloud VPN connection from the new VPC to the data center, and apply a firewall rule that blocks the overlapping IP space.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Following your company's acquisition of another company, you have been assigned the task of integrating their existing Google Cloud environment with your company's data center. Upon examination, you uncover that certain RFC 1918 IP address ranges employed in the new company's Virtual Private Cloud (VPC) conflict with the IP address space utilized in your data center. What steps should you take to establish connectivity and prevent any routing conflicts once the connectivity is established?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163970,
            "assessment_type": "multi-select",
            "prompt": {
                "question": "<p>You are in the process of setting up a single second-generation Cloud SQL MySQL database that holds crucial transactional data for the business. Your objective is to minimize data loss in the event of a significant failure. Which two functionalities should you incorporate in the solution?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Binary logging -&gt; Correct. It allows the database to record all changes to the data, and these logs can be used for backup, replication, or for auditing purposes. This feature can help in case of data loss by allowing the recovery of the database up to the point of the last recorded transaction.</p><p><br></p><p>Automated backups -&gt; Correct. It creates backups of the database at regular intervals, which can be used for disaster recovery in case of data loss. Automated backups allow for a fast and easy restore process, minimizing the amount of data that is lost in the event of a major failure.</p><p><br></p><p>Sharding -&gt; Incorrect. It splits the database into smaller, more manageable parts, allowing for improved performance and scalability. However, it does not directly address data loss.</p><p><br></p><p>Read replicas -&gt; Incorrect. It is used to improve read performance by creating copies of the database for read-only operations. It can help to improve performance, but it does not directly address data loss.</p><p><br></p><p>Semisynchronous replication -&gt; Incorrect. It provides increased data consistency by ensuring that at least one replica has received a transaction before it is committed. While it can help to minimize data loss, it does not directly address data loss in the event of a major failure.</p><p><br></p><p>https://cloud.google.com/sql/docs/mysql/backup-recovery/backups</p>",
                "answers": [
                    "<p>Binary logging</p>",
                    "<p>Automated backups</p>",
                    "<p>Sharding</p>",
                    "<p>Read replicas</p>",
                    "<p>Semisynchronous replication</p>"
                ]
            },
            "correct_response": [
                "a",
                "b"
            ],
            "section": "",
            "question_plain": "You are in the process of setting up a single second-generation Cloud SQL MySQL database that holds crucial transactional data for the business. Your objective is to minimize data loss in the event of a significant failure. Which two functionalities should you incorporate in the solution?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163972,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your company has multiple GKE clusters running in different regions. You are tasked with setting up a centralized monitoring solution to have a single view of the health and performance of all the clusters. Which approach would you take?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Anthos to centrally manage and monitor all GKE clusters. -&gt;&nbsp;Correct. Anthos provides a centralized management platform for all GKE clusters, making it the best choice for this scenario.</p><p><br></p><p>Deploy a Prometheus server in each GKE cluster and configure them to push metrics to a central Grafana dashboard. -&gt; Incorrect. While Prometheus and Grafana are popular monitoring solutions, managing separate Prometheus instances for each cluster can be cumbersome.</p><p><br></p><p>Use Google Cloud's Operations suite and set up a Workspace for each GKE cluster, then create a combined dashboard. -&gt; Incorrect. Google Cloud's Operations suite allows creating Workspaces, but setting up a separate Workspace for each cluster doesn't provide a centralized view.</p><p><br></p><p>Configure each GKE cluster to export logs and metrics to a central BigQuery dataset and create custom SQL queries to monitor the health. -&gt; Incorrect. Exporting to BigQuery can be useful for long-term analysis but may not be the best real-time monitoring solution.</p>",
                "answers": [
                    "<p>Use Anthos to centrally manage and monitor all GKE clusters.</p>",
                    "<p>Deploy a Prometheus server in each GKE cluster and configure them to push metrics to a central Grafana dashboard.</p>",
                    "<p>Use Google Cloud's Operations suite and set up a Workspace for each GKE cluster, then create a combined dashboard.</p>",
                    "<p>Configure each GKE cluster to export logs and metrics to a central BigQuery dataset and create custom SQL queries to monitor the health.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your company has multiple GKE clusters running in different regions. You are tasked with setting up a centralized monitoring solution to have a single view of the health and performance of all the clusters. Which approach would you take?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163974,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>In your organization, there is an application that operates on multiple Compute Engine instances. The objective is to establish seamless communication between your application and an on-premises service, which demands high throughput, using internal IP addresses. The goal is to minimize latency as much as possible. As a cloud architect, what recommendations should you provide in this scenario?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>You should configure a Cloud Dedicated Interconnect connection between the on-premises environment and Google Cloud. -&gt; Correct. Cloud Dedicated Interconnect provides a direct, dedicated, and private network connection between your on-premises environment and Google Cloud. This connection offers high throughput and low latency, making it suitable for demanding workloads that require seamless communication with minimal delay. By using internal IP addresses, you can ensure that the communication between the application on Compute Engine instances and the on-premises service occurs over this dedicated and high-performance connection.</p><p><br></p><p>You should use Cloud VPN to configure a VPN tunnel between the on-premises environment and Google Cloud. -&gt; Incorrect. Cloud VPN establishes a secure virtual private network (VPN) tunnel over the public internet between your on-premises environment and Google Cloud. While it provides secure connectivity, it may introduce additional latency compared to a dedicated connection like Cloud Dedicated Interconnect.</p><p><br></p><p>You should configure a direct peering connection between the on-premises environment and Google Cloud. -&gt; Incorrect. Direct peering allows you to establish a direct network connection between your on-premises environment and Google Cloud using a peering provider. While direct peering can offer a fast and dedicated connection, it might not provide the same level of throughput and latency benefits as Cloud Dedicated Interconnect.</p><p><br></p><p>You should use OpenVPN to configure a VPN tunnel between the on-premises environment and Google Cloud. -&gt; Incorrect. OpenVPN is an open-source VPN software that can be used to establish a VPN tunnel between your on-premises environment and Google Cloud. While it provides secure connectivity, it may not offer the same level of performance, throughput, and low latency as Cloud Dedicated Interconnect.</p><p><br></p><p>https://cloud.google.com/network-connectivity/docs/interconnect</p>",
                "answers": [
                    "<p>You should configure a Cloud Dedicated Interconnect connection between the on-premises environment and Google Cloud.</p>",
                    "<p>You should use Cloud VPN to configure a VPN tunnel between the on-premises environment and Google Cloud.</p>",
                    "<p>You should configure a direct peering connection between the on-premises environment and Google Cloud.</p>",
                    "<p>You should use OpenVPN to configure a VPN tunnel between the on-premises environment and Google Cloud.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "In your organization, there is an application that operates on multiple Compute Engine instances. The objective is to establish seamless communication between your application and an on-premises service, which demands high throughput, using internal IP addresses. The goal is to minimize latency as much as possible. As a cloud architect, what recommendations should you provide in this scenario?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163976,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You have been hired to design a disaster recovery solution for a customer's Google Cloud Platform (GCP) environment. The customer requires that the solution provide low Recovery Time Objective (RTO) and Recovery Point Objective (RPO) in the event of a disaster. Which of the following GCP services would you use to meet these requirements?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>To answer this question, we need to understand the concepts of Recovery Time Objective (RTO) and Recovery Point Objective (RPO).</p><ol><li><p>RTO is the targeted duration of time within which a business process must be restored after a disaster (or disruption) in order to avoid unacceptable consequences associated with a break in that business process. Essentially, it's how quickly you need to be back up and running.</p></li><li><p>RPO is the maximum targeted period in which data (transactions) might be lost from an IT service due to a major incident. In other words, it's how much data you can afford to lose before it seriously impacts your operation.</p></li></ol><p><br></p><p>Cloud Storage and Compute Engine with Persistent Disks. -&gt;&nbsp;Correct.&nbsp;Cloud Storage is designed for 99.999999999% durability and has various storage class options (Multi-regional, regional, nearline, coldline, and archive) for different use cases and access frequencies. This will ensure that data is not lost (low RPO). Compute Engine with Persistent Disks is a service that provides virtual machines that can be quickly spun up and shut down. This is beneficial for disaster recovery because these instances can be quickly started to restore service (low RTO). Persistent disks are network storage devices that persist data independent of the life of an instance, which helps to prevent data loss.</p><p><br></p><p>Cloud Storage and Cloud Functions -&gt;&nbsp;Incorrect. Cloud Functions is a serverless execution environment for building and connecting cloud services but it doesn't directly support a disaster recovery solution.</p><p><br></p><p>Cloud SQL and BigQuery -&gt;&nbsp;Incorrect. Cloud SQL and BigQuery are focused on database services, but they alone cannot ensure low RTO and RPO.</p><p><br></p><p>Cloud Storage only -&gt;&nbsp;Incorrect. It would be good for ensuring low RPO (minimal data loss), but it doesn't address the RTO requirement to quickly restore services.</p><p><br></p><p>https://cloud.google.com/compute/docs/disks#pdspecs</p>",
                "answers": [
                    "<p>Cloud Storage and Cloud Functions</p>",
                    "<p>Cloud SQL and BigQuery</p>",
                    "<p>Cloud Storage only</p>",
                    "<p>Cloud Storage and Compute Engine with Persistent Disks</p>"
                ]
            },
            "correct_response": [
                "d"
            ],
            "section": "",
            "question_plain": "You have been hired to design a disaster recovery solution for a customer's Google Cloud Platform (GCP) environment. The customer requires that the solution provide low Recovery Time Objective (RTO) and Recovery Point Objective (RPO) in the event of a disaster. Which of the following GCP services would you use to meet these requirements?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163978,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are designing a cloud solution for a financial services company that requires strict compliance with data security regulations. Your application needs to handle sensitive customer data, and you must ensure all data at rest and in transit is appropriately encrypted. Which of the following approaches best aligns with security and compliance standards for managing encryption keys and secrets?</p>",
                "relatedLectureIds": [],
                "links": [],
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Cloud Key Management Service (KMS) to manage encryption keys and Cloud Identity-Aware Proxy (IAP) to handle access to those keys. -&gt; Correct. Cloud KMS provides managed security and control over encryption keys, while IAP helps control access to applications and services based on identity, thus ensuring both key security and proper access management.</p><p><br></p><p>Store encryption keys in a regular cloud storage bucket and manage access using IAM roles. -&gt; Incorrect. Storing encryption keys directly in cloud storage without a dedicated security service is risky and does not comply with best practices for key management and data security.</p><p><br></p><p>Embed encryption keys directly into application code to ensure they are readily available for use in encryption and decryption processes. -&gt; Incorrect. Hard-coding encryption keys in the application code is insecure as it exposes the keys in source control and to anyone who has access to the application code.</p><p><br></p><p>Utilize self-managed encryption keys stored on-premises, and use VPN connections to access these keys from cloud services as needed. -&gt; Incorrect. While using on-premises keys adds a level of control, it complicates the architecture and can introduce latency and complexity in key retrieval during critical operations, potentially violating compliance requirements for quick data access.</p>",
                "answers": [
                    "<p>Use Cloud Key Management Service (KMS) to manage encryption keys and Cloud Identity-Aware Proxy (IAP) to handle access to those keys.</p>",
                    "<p>Store encryption keys in a regular cloud storage bucket and manage access using IAM roles.</p>",
                    "<p>Embed encryption keys directly into application code to ensure they are readily available for use in encryption and decryption processes.</p>",
                    "<p>Utilize self-managed encryption keys stored on-premises, and use VPN connections to access these keys from cloud services as needed.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are designing a cloud solution for a financial services company that requires strict compliance with data security regulations. Your application needs to handle sensitive customer data, and you must ensure all data at rest and in transit is appropriately encrypted. Which of the following approaches best aligns with security and compliance standards for managing encryption keys and secrets?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163980,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are designing a solution for a customer who needs to collect and analyze large amounts of log data from their web applications. The customer wants to store the log data for a minimum of 7 years for compliance purposes. Which of the following Google Cloud Platform (GCP) services would you use to meet this requirement?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Cloud Storage -&gt; Correct. Cloud Storage allows world-wide storage and retrieval of any amount of data at any time. You can use Cloud Storage for a range of scenarios including serving website content, storing data for archival and disaster recovery, or distributing large data objects to users via direct download.</p><p><br></p><p>Bigtable -&gt; Incorrect. Bigtable is a high-performance, NoSQL database service provided by Google Cloud. While Bigtable is well-suited for applications that require high-speed data ingestion and low-latency queries, it may not be the most efficient choice for long-term storage and retention of log data for 7 years.</p><p><br></p><p>Cloud SQL -&gt; Incorrect. Cloud SQL is a fully managed relational database service provided by Google Cloud. It is optimized for transactional workloads and may not be the ideal choice for storing and retaining large amounts of log data for an extended period, especially if the data does not have a structured schema typically associated with relational databases.</p><p><br></p><p>Cloud Datastore -&gt; Incorrect. Cloud Datastore is a NoSQL document database provided by Google Cloud. It is designed for scalable applications and may not be the best choice for storing and retaining log data for compliance purposes, especially when dealing with large amounts of data over a long period.</p><p><br></p><p>https://cloud.google.com/storage/docs</p>",
                "answers": [
                    "<p>Bigtable</p>",
                    "<p>Cloud Storage</p>",
                    "<p>Cloud SQL</p>",
                    "<p>Cloud Datastore</p>"
                ]
            },
            "correct_response": [
                "b"
            ],
            "section": "",
            "question_plain": "You are designing a solution for a customer who needs to collect and analyze large amounts of log data from their web applications. The customer wants to store the log data for a minimum of 7 years for compliance purposes. Which of the following Google Cloud Platform (GCP) services would you use to meet this requirement?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163982,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>What is the recommended approach for securing access to Google Cloud resources for a multi-tier application architecture, such as a web frontend, application backend, and a database?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Create separate service accounts for each tier, and use Google Cloud IAM roles to grant the minimum necessary permissions to each tier. -&gt;&nbsp;Correct. When securing access to Google Cloud resources for a multi-tier application architecture, it is recommended to create separate service accounts for each tier and use Google Cloud IAM roles to grant the minimum necessary permissions to each tier. This approach follows the principle of least privilege, which means that each tier has only the permissions required to perform its specific tasks and no more. By using separate service accounts and IAM roles, it is possible to enforce fine-grained access control and minimize the risk of unauthorized access to resources.</p><p><br></p><p>Create a single service account with the necessary permissions and use it for all tiers. -&gt;&nbsp;Incorrect. It is not recommended because using a single service account for all tiers creates a higher risk of unauthorized access and makes it difficult to enforce fine-grained access control.</p><p><br></p><p>Use Google Cloud IAM roles to grant the necessary permissions to each Google Cloud user who requires access to the resources. -&gt; Incorrect. It is also not recommended because granting permissions directly to users violates the principle of least privilege and makes it difficult to manage access control in a scalable way.</p><p><br></p><p>Use Google Cloud IAM roles to grant the necessary permissions to each Google Cloud group, and add the appropriate users to the relevant groups. -&gt;&nbsp;Incorrect. It is a possible solution, but it can become difficult to manage as the number of users and groups increases, and it may be less flexible than using service accounts and IAM roles.</p><p><br></p><p>https://cloud.google.com/iam/docs/creating-managing-service-accounts</p><p>https://cloud.google.com/iam/docs/service-accounts</p>",
                "answers": [
                    "<p>Create separate service accounts for each tier, and use Google Cloud IAM roles to grant the minimum necessary permissions to each tier.</p>",
                    "<p>Create a single service account with the necessary permissions and use it for all tiers.</p>",
                    "<p>Use Google Cloud IAM roles to grant the necessary permissions to each Google Cloud user who requires access to the resources.</p>",
                    "<p>Use Google Cloud IAM roles to grant the necessary permissions to each Google Cloud group, and add the appropriate users to the relevant groups.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "What is the recommended approach for securing access to Google Cloud resources for a multi-tier application architecture, such as a web frontend, application backend, and a database?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163984,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your organization is developing a new multi-tier web application. The application architecture consists of a web front end, a REST API backend, and a relational database. The application is expected to experience heavy traffic, so it needs to be highly scalable and resilient. As a cloud architect, which of the following deployment strategies would you recommend for this application on Google Cloud?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Deploy the web front end and REST API backend on separate App Engine services, and the database on Cloud Spanner. -&gt;&nbsp;Correct. App Engine is well suited to serve both the front end and the REST API backend, as it can scale automatically based on the incoming traffic. Cloud Spanner is a good choice for the database tier as it is a fully managed, relational database that can scale horizontally while maintaining strong consistency across all regions.</p><p><br></p><p>Deploy the web front end on Compute Engine, the REST API backend on GKE, and the database on Cloud Bigtable. -&gt; Incorrect. While Compute Engine and GKE are robust solutions, they require more operational overhead compared to platform services like App Engine. Cloud Bigtable, while excellent for large analytical and operational workloads, does not provide the relational database structure typically required for web applications.</p><p><br></p><p>Deploy the entire application on a single GKE cluster, using different namespaces for the front end, the backend, and the database. -&gt;&nbsp;Incorrect. Deploying the entire application on a single GKE cluster does not provide the best level of isolation between application tiers.</p><p><br></p><p>Deploy the web front end on Cloud Functions, the REST API backend on App Engine, and the database on Firestore. -&gt;&nbsp;Incorrect. Cloud Functions is not the best choice for serving the web front end, especially in an application expected to experience heavy traffic. Firestore, although a scalable database solution, does not support the SQL queries and transactions as efficiently as Cloud Spanner does for complex web applications.</p>",
                "answers": [
                    "<p>Deploy the web front end and REST API backend on separate App Engine services, and the database on Cloud Spanner.</p>",
                    "<p>Deploy the web front end on Compute Engine, the REST API backend on GKE, and the database on Cloud Bigtable.</p>",
                    "<p>Deploy the entire application on a single GKE cluster, using different namespaces for the front end, the backend, and the database.</p>",
                    "<p>Deploy the web front end on Cloud Functions, the REST API backend on App Engine, and the database on Firestore.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your organization is developing a new multi-tier web application. The application architecture consists of a web front end, a REST API backend, and a relational database. The application is expected to experience heavy traffic, so it needs to be highly scalable and resilient. As a cloud architect, which of the following deployment strategies would you recommend for this application on Google Cloud?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163986,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>A company is planning to deploy a large-scale e-commerce platform on Google Cloud Platform (GCP) that must be able to handle millions of transactions per day and provide fast and reliable performance. The platform must also provide scalable and secure storage for product information, customer data, and transaction records. Additionally, the platform must be able to support real-time analytics and data processing. Which of the following options would be the most effective approach to meet these requirements while also optimizing cost?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Cloud Spanner to store product information, customer data, and transaction records, and use BigQuery for real-time analytics and data processing. -&gt;&nbsp;Correct. The reason for this is that Cloud Spanner is a horizontally scalable, highly available, and globally distributed relational database that can handle large volumes of data and provide strong consistency. It can also provide high write throughput and low latency reads, making it an ideal choice for e-commerce platforms that need to handle millions of transactions per day. BigQuery, on the other hand, is a fast and scalable data warehouse that can handle real-time analytics and data processing. It allows for easy querying of large datasets and provides results in seconds, making it ideal for e-commerce platforms that need to analyze large volumes of data quickly. Using Cloud Spanner and BigQuery together can provide a scalable, reliable, and high-performance e-commerce platform that can handle millions of transactions per day while also supporting real-time analytics and data processing. This option also minimizes the use of additional services, which helps optimize costs.</p><p><br></p><p>Use Cloud SQL to store product information and customer data, and use BigQuery for real-time analytics and data processing. Use Cloud Storage for transaction records and serving product images. -&gt; Incorrect. Cloud SQL is a managed relational database service, but it may not provide the scalability and performance required to handle millions of transactions per day efficiently.</p><p><br></p><p>Use Cloud Datastore to store product information and customer data, and use Cloud Dataflow for real-time analytics and data processing. Use Cloud Storage for transaction records and serving product images. -&gt; Incorrect. Cloud Datastore is a NoSQL document database, which may not be the most suitable choice for storing product information and customer data in a large-scale e-commerce platform.</p><p><br></p><p>Use Cloud Firestore to store product information, customer data, and transaction records, and use Cloud Dataproc for real-time analytics and data processing. -&gt; Incorrect. Cloud Firestore is a NoSQL document database, but it may not offer the same scalability and performance as Cloud Spanner.</p>",
                "answers": [
                    "<p>Use Cloud SQL to store product information and customer data, and use BigQuery for real-time analytics and data processing. Use Cloud Storage for transaction records and serving product images.</p>",
                    "<p>Use Cloud Spanner to store product information, customer data, and transaction records, and use BigQuery for real-time analytics and data processing.</p>",
                    "<p>Use Cloud Datastore to store product information and customer data, and use Cloud Dataflow for real-time analytics and data processing. Use Cloud Storage for transaction records and serving product images.</p>",
                    "<p>Use Cloud Firestore to store product information, customer data, and transaction records, and use Cloud Dataproc for real-time analytics and data processing.</p>"
                ]
            },
            "correct_response": [
                "b"
            ],
            "section": "",
            "question_plain": "A company is planning to deploy a large-scale e-commerce platform on Google Cloud Platform (GCP) that must be able to handle millions of transactions per day and provide fast and reliable performance. The platform must also provide scalable and secure storage for product information, customer data, and transaction records. Additionally, the platform must be able to support real-time analytics and data processing. Which of the following options would be the most effective approach to meet these requirements while also optimizing cost?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163988,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your organization is deploying a data-intensive application on GCP. The application requires 50 TB of storage for data that will be infrequently accessed - once per quarter. The data must be available for immediate access when needed, but cost optimization is a key requirement. Which storage class should you use?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Coldline Storage Class for Cloud Storage -&gt;&nbsp;Correct. Coldline storage is a cost-effective solution for storing infrequently accessed data that still requires immediate access. It offers lower costs than Nearline and Standard storage, while providing faster access than Archive storage.</p><p><br></p><p>Archive Storage Class for Cloud Storage -&gt; Incorrect. While Archive storage is the cheapest option, data retrieval can take several hours, which violates the requirement for immediate access.</p><p><br></p><p>Nearline Storage Class for Cloud Storage. -&gt; Incorrect. Nearline storage is more cost-effective than standard storage for data that's accessed less than once a month, but there are cheaper options for infrequently accessed data.</p><p><br></p><p>Standard Storage Class for Cloud Storage. -&gt; Incorrect. While this class offers high availability and performance, it's the most expensive for storing large amounts of infrequently accessed data.</p>",
                "answers": [
                    "<p>Coldline Storage Class for Cloud Storage</p>",
                    "<p>Archive Storage Class for Cloud Storage</p>",
                    "<p>Nearline Storage Class for Cloud Storage.</p>",
                    "<p>Standard Storage Class for Cloud Storage.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your organization is deploying a data-intensive application on GCP. The application requires 50 TB of storage for data that will be infrequently accessed - once per quarter. The data must be available for immediate access when needed, but cost optimization is a key requirement. Which storage class should you use?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163990,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Your company is working on a real-time analytics solution that processes vast amounts of data collected from IoT devices across the globe. The system must be capable of low-latency read and write access, high throughput, and horizontal scalability. The data will be analyzed using both batch and stream processing. Which Google Cloud service would be the most appropriate solution for this scenario?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Google Bigtable -&gt;&nbsp;Correct. Google Bigtable is an excellent choice for this scenario, as it is a NoSQL big data database service that is designed to handle the high-throughput, low-latency workloads that are common in real-time analytics. It also scales horizontally to handle large volumes of data, making it ideal for the scenario.</p><p><br></p><p>BigQuery -&gt; Incorrect. BigQuery is excellent for running fast, SQL-like queries against large datasets. However, it's not designed for the high volume, high-speed inserts for real-time analytics that the scenario demands.</p><p><br></p><p>Cloud Firestore -&gt; Incorrect. Cloud Firestore is designed for serverless applications, and while it is a NoSQL document database that can scale, it doesn't provide the high throughput and low latency capabilities that are necessary for handling real-time analytics with IoT data.</p><p><br></p><p>Cloud Spanner -&gt; Incorrect. Cloud Spanner is a relational database that is excellent for high availability and consistency, but it may not be ideal for the high throughput, low latency requirements of a real-time analytics solution with large amounts of data from IoT devices.</p>",
                "answers": [
                    "<p>Google Bigtable</p>",
                    "<p>BigQuery</p>",
                    "<p>Cloud Firestore</p>",
                    "<p>Cloud Spanner</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "Your company is working on a real-time analytics solution that processes vast amounts of data collected from IoT devices across the globe. The system must be capable of low-latency read and write access, high throughput, and horizontal scalability. The data will be analyzed using both batch and stream processing. Which Google Cloud service would be the most appropriate solution for this scenario?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163992,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are a cloud architect designing a new application for a global financial services company. The application will handle real-time transaction processing across multiple regions and should be resilient to regional outages. Your solution should also minimize latency. Which of the following is the most appropriate design for this use case?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Google Cloud Spanner as your primary database with multi-region configuration and Cloud Load Balancing to distribute the traffic. -&gt;&nbsp;Correct. Spanner provides strong consistency, global transaction support, and can be configured across multiple regions, making it an excellent choice for global real-time transaction processing. The use of Cloud Load Balancing helps to distribute traffic and reduce latency.</p><p><br></p><p>Use Google Cloud Bigtable as your primary database with regional replication and Cloud Load Balancing for distributing traffic. -&gt;&nbsp;Incorrect. While Bigtable is great for large analytical and operational workloads, it may not be ideal for real-time transaction processing needed by financial applications.</p><p><br></p><p>Use Google Cloud Datastore as your primary database with multi-region distribution and Cloud CDN for cache optimization. -&gt;&nbsp;Incorrect. While Google Cloud Datastore provides strong consistency and multi-region distribution, it's not optimized for real-time transaction processing and doesn't inherently support financial services transaction handling.</p><p><br></p><p>Use Google Cloud SQL with multi-region replication and Cloud CDN for cache optimization. -&gt; Incorrect. Cloud SQL provides traditional relational database services but lacks the horizontal scalability and global transaction support needed for this specific use case.</p>",
                "answers": [
                    "<p>Use Google Cloud Spanner as your primary database with multi-region configuration and Cloud Load Balancing to distribute the traffic.</p>",
                    "<p>Use Google Cloud Bigtable as your primary database with regional replication and Cloud Load Balancing for distributing traffic.</p>",
                    "<p>Use Google Cloud Datastore as your primary database with multi-region distribution and Cloud CDN for cache optimization.</p>",
                    "<p>Use Google Cloud SQL with multi-region replication and Cloud CDN for cache optimization.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are a cloud architect designing a new application for a global financial services company. The application will handle real-time transaction processing across multiple regions and should be resilient to regional outages. Your solution should also minimize latency. Which of the following is the most appropriate design for this use case?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163994,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are the cloud architect for a multinational corporation which has decided to migrate its on-premises data warehouse to Google Cloud. The data warehouse needs to handle several petabytes of data, with frequent, unpredictable spikes in query activity. What approach should you recommend for scalable data warehouse solution on GCP?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use BigQuery for both data storage and analysis. -&gt;&nbsp;Correct. BigQuery is a fully managed, serverless data warehouse solution provided by Google Cloud. It is designed to handle massive datasets and can scale seamlessly to handle several petabytes of data. BigQuery also provides powerful querying capabilities, allowing for efficient analysis of the data. It is well-suited for handling frequent, unpredictable spikes in query activity, as it automatically scales resources to meet demand. Using BigQuery for both data storage and analysis simplifies the architecture and leverages the native capabilities of the platform.</p><p><br></p><p>Use Cloud Storage for data storage, with scheduled queries running in Dataflow. -&gt;&nbsp;Incorrect. While Cloud Storage is good for storing large amounts of data, it is not designed to serve as a scalable data warehouse. Dataflow is mainly used for processing data, not designed for querying large data sets.</p><p><br></p><p>Use Bigtable for data storage, with analysis using Data Studio. -&gt;&nbsp;Incorrect. Bigtable is designed for high throughput, low latency workloads, and while it can store large amounts of data, it does not have the SQL capabilities necessary for data warehousing. Data Studio is for visualizing data, not querying large datasets.</p><p><br></p><p>Use Cloud SQL for data storage, with Dataflow for analysis. -&gt;&nbsp;Incorrect. Cloud SQL is a managed relational database service, which may not be the ideal choice for handling several petabytes of data. It is optimized for online transaction processing (OLTP) workloads rather than large-scale data warehousing. While Dataflow is a flexible and scalable data processing service, it is primarily used for ETL (extract, transform, load) and batch processing tasks, and may not provide the same level of performance and efficiency as BigQuery for ad-hoc queries and analytics.</p>",
                "answers": [
                    "<p>Use BigQuery for both data storage and analysis.</p>",
                    "<p>Use Cloud Storage for data storage, with scheduled queries running in Dataflow.</p>",
                    "<p>Use Bigtable for data storage, with analysis using Data Studio.</p>",
                    "<p>Use Cloud SQL for data storage, with Dataflow for analysis.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are the cloud architect for a multinational corporation which has decided to migrate its on-premises data warehouse to Google Cloud. The data warehouse needs to handle several petabytes of data, with frequent, unpredictable spikes in query activity. What approach should you recommend for scalable data warehouse solution on GCP?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163996,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Consider a scenario where a large online retailer needs to implement a highly available and scalable NoSQL solution for its e-commerce platform. The solution must handle large amounts of traffic during peak periods, provide fast and reliable performance, and ensure the security of customer data. What is the most appropriate solution for the large online retailer to implement a highly available and scalable solution for its e-commerce platform while handling large amounts of traffic during peak periods, providing fast and reliable performance, and ensuring the security of customer data?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use Google Kubernetes Engine for the e-commerce platform with autoscaling and use Cloud Firestore for storage. -&gt;&nbsp;Correct. Google Kubernetes Engine (GKE) provides a highly available and scalable container orchestration platform based on Kubernetes. It allows for automatic scaling and load balancing, making it suitable for handling large amounts of traffic during peak periods. Cloud Firestore is a NoSQL document database provided by Google Cloud, offering scalability, fast and reliable performance, and built-in security features. It is well-suited for storing structured NoSQL data and ensuring the security of customer data.</p><p><br></p><p>Use App Engine for the e-commerce platform with a single instance and use Cloud Storage for storage. -&gt;&nbsp;Incorrect. App Engine is a platform-as-a-service (PaaS) offering that automatically scales based on demand, but it may not provide the flexibility and fine-grained control required for this scenario. Cloud Storage is an object storage service and may not be the best choice for storing structured data in a NoSQL format.</p><p><br></p><p>Use Compute Engine with autoscaling and load balancing for the e-commerce platform and use Cloud SQL for storage. -&gt;&nbsp;Incorrect. While Compute Engine with autoscaling and load balancing can handle traffic and provide scalability, Cloud SQL is a managed relational database service and may not be the best fit for a NoSQL solution.</p><p><br></p><p>Use Compute Engine VM single instance for the e-commerce platform and use Cloud&nbsp;SQL for storage. -&gt;&nbsp;Incorrect. A single Compute Engine VM instance does not provide the scalability and high availability required for handling large amounts of traffic during peak periods. Cloud SQL, being a managed relational database service, may not align well with the requirements of a NoSQL solution.</p>",
                "answers": [
                    "<p>Use App Engine for the e-commerce platform with a single instance and use Cloud Storage for storage.</p>",
                    "<p>Use Compute Engine with autoscaling and load balancing for the e-commerce platform and use Cloud SQL for storage.</p>",
                    "<p>Use Compute Engine VM single instance for the e-commerce platform and use Cloud&nbsp;SQL for storage.</p>",
                    "<p>Use Google Kubernetes Engine for the e-commerce platform with autoscaling and use Cloud Firestore for storage.</p>"
                ]
            },
            "correct_response": [
                "d"
            ],
            "section": "",
            "question_plain": "Consider a scenario where a large online retailer needs to implement a highly available and scalable NoSQL solution for its e-commerce platform. The solution must handle large amounts of traffic during peak periods, provide fast and reliable performance, and ensure the security of customer data. What is the most appropriate solution for the large online retailer to implement a highly available and scalable solution for its e-commerce platform while handling large amounts of traffic during peak periods, providing fast and reliable performance, and ensuring the security of customer data?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82163998,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>Which of the following steps should be taken to ensure maximum data transfer speed while migrating 5TB of private data from on-premises to Google Cloud Storage?</p>",
                "relatedLectureIds": "",
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Use a migration tool to automate the transfer process -&gt; Correct. Using a migration tool like Google Cloud Storage Transfer Service, gsutil, or Cloud Data Transfer can help to automate the transfer process and ensure that your data is secure and well-managed during the migration. This option is faster and more secure than manually copying files or using a low-speed internet connection. </p><p><br></p><p>Use a low-speed internet connection -&gt;&nbsp;Incorrect. It is incorrect as it suggests using a low-speed internet connection which would slow down the transfer process. </p><p><br></p><p>Transfer all the data in one large piece -&gt; Incorrect. It is incorrect as transferring all the data in one large piece can also slow down the transfer process and may even cause errors or data loss. </p><p><br></p><p>Transfer data during peak network hours -&gt; Incorrect. It is incorrect as transferring data during peak network hours can result in network congestion and may slow down the transfer process.</p>",
                "answers": [
                    "<p>Use a low-speed internet connection</p>",
                    "<p>Use a migration tool to automate the transfer process</p>",
                    "<p>Transfer all the data in one large piece</p>",
                    "<p>Transfer data during peak network hours</p>"
                ]
            },
            "correct_response": [
                "b"
            ],
            "section": "",
            "question_plain": "Which of the following steps should be taken to ensure maximum data transfer speed while migrating 5TB of private data from on-premises to Google Cloud Storage?",
            "related_lectures": []
        },
        {
            "_class": "assessment",
            "id": 82164000,
            "assessment_type": "multiple-choice",
            "prompt": {
                "question": "<p>You are a cloud architect working on a large-scale application that leverages various Google Cloud services, including Bigtable, Firestore, and Pub/Sub. Your development team is transitioning from a monolithic architecture to a microservices architecture, and you are tasked with implementing a testing strategy that includes the use of cloud emulators to ensure each service is properly tested in isolation before integration. Which of the following strategies would be most effective for managing this implementation using Google Cloud emulators?</p>",
                "relatedLectureIds": [],
                "links": [],
                "feedbacks": [
                    "",
                    "",
                    "",
                    ""
                ],
                "explanation": "<p>Configure separate CI/CD pipelines to include stages that set up and tear down emulators for each service, ensuring isolated environment testing during development. -&gt;&nbsp;Correct. Using CI/CD pipelines to manage the lifecycle of emulators for each microservice allows isolated testing and ensures that each component interacts properly with emulated versions of its dependencies, simulating production conditions without affecting the live environment.</p><p><br></p><p>Utilize the Google Cloud SDK to deploy emulators for Bigtable, Firestore, and Pub/Sub directly in the production environment for live testing. -&gt;&nbsp;Incorrect. Deploying emulators in a production environment is not recommended as it could lead to performance issues and does not replicate the live environment accurately.</p><p><br></p><p>Implement a single emulator that mimics all services (Bigtable, Firestore, and Pub/Sub) to simplify the testing process and reduce resource usage. -&gt;&nbsp;Incorrect. No single emulator can mimic all these services, and using one might lead to insufficient testing as different services have unique characteristics and behaviors.</p><p><br></p><p>Only use local machine emulators for development and skip CI/CD integration, relying on developer discipline to conduct necessary tests. -&gt;&nbsp;Incorrect. Relying solely on local testing without integrating emulators into CI/CD pipelines misses opportunities for automated, repeatable testing and can lead to inconsistencies in how tests are run by different developers.</p>",
                "answers": [
                    "<p>Configure separate CI/CD pipelines to include stages that set up and tear down emulators for each service, ensuring isolated environment testing during development.</p>",
                    "<p>Utilize the Google Cloud SDK to deploy emulators for Bigtable, Firestore, and Pub/Sub directly in the production environment for live testing.</p>",
                    "<p>Implement a single emulator that mimics all services (Bigtable, Firestore, and Pub/Sub) to simplify the testing process and reduce resource usage.</p>",
                    "<p>Only use local machine emulators for development and skip CI/CD integration, relying on developer discipline to conduct necessary tests.</p>"
                ]
            },
            "correct_response": [
                "a"
            ],
            "section": "",
            "question_plain": "You are a cloud architect working on a large-scale application that leverages various Google Cloud services, including Bigtable, Firestore, and Pub/Sub. Your development team is transitioning from a monolithic architecture to a microservices architecture, and you are tasked with implementing a testing strategy that includes the use of cloud emulators to ensure each service is properly tested in isolation before integration. Which of the following strategies would be most effective for managing this implementation using Google Cloud emulators?",
            "related_lectures": []
        }
    ]
}